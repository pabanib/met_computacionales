{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "748fd4a3-51b9-4d29-b0ff-32380a1fecd1",
   "metadata": {
    "id": "748fd4a3-51b9-4d29-b0ff-32380a1fecd1"
   },
   "source": [
    "# Modelos lineales regularizados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6ee349-aaeb-4cac-b836-69d73db29cbc",
   "metadata": {
    "id": "ef6ee349-aaeb-4cac-b836-69d73db29cbc"
   },
   "source": [
    "## Instalación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c78d0f-3fce-4ea5-9640-51e2178e6a7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1653562133050,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "53c78d0f-3fce-4ea5-9640-51e2178e6a7f",
    "outputId": "4db812fc-552d-4481-bc25-e52b91519b3a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'R version 4.1.3 (2022-03-10)'"
      ],
      "text/latex": [
       "'R version 4.1.3 (2022-03-10)'"
      ],
      "text/markdown": [
       "'R version 4.1.3 (2022-03-10)'"
      ],
      "text/plain": [
       "[1] \"R version 4.1.3 (2022-03-10)\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "R.version.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe8f443-5860-4e36-8464-160f18be7efc",
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1653562133052,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "8fe8f443-5860-4e36-8464-160f18be7efc"
   },
   "outputs": [],
   "source": [
    "packages <- c(\"devtools\"\n",
    "  ,\"randomForest\" \n",
    "  ,\"rpart\" # decision tree\n",
    "  ,\"rpart.plot\" # enhanced tree plots\n",
    "  ,\"ROCR\"\n",
    "  ,\"Hmisc\"\n",
    "  ,\"corrplot\"\n",
    "  ,\"texreg\"\n",
    "  ,\"glmnet\"\n",
    "  ,\"reshape2\"\n",
    "  ,\"knitr\"\n",
    "  ,\"xtable\"\n",
    "  ,\"lars\"\n",
    "  ,\"ggplot2\"\n",
    "  ,\"matrixStats\"\n",
    "  ,\"plyr\"\n",
    "  ,\"stargazer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9327ad3-c104-43a4-97a6-0411b6c4a0fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 330026,
     "status": "ok",
     "timestamp": 1653562463051,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "f9327ad3-c104-43a4-97a6-0411b6c4a0fb",
    "outputId": "576bc896-0b0d-4e7b-c30c-bf1663b81820"
   },
   "outputs": [],
   "source": [
    "not_installed <- !packages %in% installed.packages()\n",
    "if (any(not_installed)) install.packages(packages[not_installed])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c606dad0-a3ce-4106-b8b5-70a0e8f89db8",
   "metadata": {
    "id": "c606dad0-a3ce-4106-b8b5-70a0e8f89db8"
   },
   "source": [
    "## Preparación de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "964f0a66-d504-40a0-adf2-a456f05299dd",
   "metadata": {
    "executionInfo": {
     "elapsed": 4673,
     "status": "ok",
     "timestamp": 1653562467706,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "964f0a66-d504-40a0-adf2-a456f05299dd"
   },
   "outputs": [],
   "source": [
    "unzip(zipfile = 'Datos/socialneighbor.zip')\n",
    "social <- read.csv('socialneighbor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffab48b6-4390-414e-811d-e00960b99091",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1653562467706,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "ffab48b6-4390-414e-811d-e00960b99091",
    "outputId": "90d77cce-44b3-4c6e-9b40-64edd73ee2ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'sex'</li><li>'yob'</li><li>'g2000'</li><li>'g2002'</li><li>'g2004'</li><li>'p2000'</li><li>'p2002'</li><li>'cluster'</li><li>'votedav'</li><li>'dem'</li><li>'nov'</li><li>'aug'</li><li>'city'</li><li>'hh_id'</li><li>'hh_size'</li><li>'totalpopulation_estimate'</li><li>'percent_male'</li><li>'percent_female'</li><li>'median_age'</li><li>'percent_under5years'</li><li>'percent_5to9years'</li><li>'percent_10to14years'</li><li>'percent_15to19years'</li><li>'percent_20to24years'</li><li>'percent_25to34years'</li><li>'percent_35to44years'</li><li>'percent_45to54years'</li><li>'percent_55to59years'</li><li>'percent_60to64years'</li><li>'percent_65to74years'</li><li>'percent_75to84years'</li><li>'percent_85yearsandolder'</li><li>'percent_18yearsandolder'</li><li>'percent_21yearsandover'</li><li>'percent_62yearsandover'</li><li>'percent_65yearsandover'</li><li>'percent_white'</li><li>'percent_black'</li><li>'percent_amindian_alaskan'</li><li>'percent_asian'</li><li>'percent_nativeandother'</li><li>'percent_other_nativeandother'</li><li>'percent_hispanicorlatino'</li><li>'percent_race_other'</li><li>'median_income'</li><li>'mean_income'</li><li>'employ_16'</li><li>'unemploy_16'</li><li>'unemploy_20to64'</li><li>'employ_20to64'</li><li>'employ_rename_20to64'</li><li>'hsorhigher'</li><li>'bach_orhigher'</li><li>'less9thgrade'</li><li>'grade9to12'</li><li>'highschool'</li><li>'somecollege'</li><li>'assoc'</li><li>'bachelors'</li><li>'grad'</li><li>'outcome_voted'</li><li>'treatment_dum'</li><li>'treat_hawthorne'</li><li>'treat_civic'</li><li>'treat_neighbors'</li><li>'treat_self'</li><li>'randn'</li><li>'oneperhh'</li><li>'p2004'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'sex'\n",
       "\\item 'yob'\n",
       "\\item 'g2000'\n",
       "\\item 'g2002'\n",
       "\\item 'g2004'\n",
       "\\item 'p2000'\n",
       "\\item 'p2002'\n",
       "\\item 'cluster'\n",
       "\\item 'votedav'\n",
       "\\item 'dem'\n",
       "\\item 'nov'\n",
       "\\item 'aug'\n",
       "\\item 'city'\n",
       "\\item 'hh\\_id'\n",
       "\\item 'hh\\_size'\n",
       "\\item 'totalpopulation\\_estimate'\n",
       "\\item 'percent\\_male'\n",
       "\\item 'percent\\_female'\n",
       "\\item 'median\\_age'\n",
       "\\item 'percent\\_under5years'\n",
       "\\item 'percent\\_5to9years'\n",
       "\\item 'percent\\_10to14years'\n",
       "\\item 'percent\\_15to19years'\n",
       "\\item 'percent\\_20to24years'\n",
       "\\item 'percent\\_25to34years'\n",
       "\\item 'percent\\_35to44years'\n",
       "\\item 'percent\\_45to54years'\n",
       "\\item 'percent\\_55to59years'\n",
       "\\item 'percent\\_60to64years'\n",
       "\\item 'percent\\_65to74years'\n",
       "\\item 'percent\\_75to84years'\n",
       "\\item 'percent\\_85yearsandolder'\n",
       "\\item 'percent\\_18yearsandolder'\n",
       "\\item 'percent\\_21yearsandover'\n",
       "\\item 'percent\\_62yearsandover'\n",
       "\\item 'percent\\_65yearsandover'\n",
       "\\item 'percent\\_white'\n",
       "\\item 'percent\\_black'\n",
       "\\item 'percent\\_amindian\\_alaskan'\n",
       "\\item 'percent\\_asian'\n",
       "\\item 'percent\\_nativeandother'\n",
       "\\item 'percent\\_other\\_nativeandother'\n",
       "\\item 'percent\\_hispanicorlatino'\n",
       "\\item 'percent\\_race\\_other'\n",
       "\\item 'median\\_income'\n",
       "\\item 'mean\\_income'\n",
       "\\item 'employ\\_16'\n",
       "\\item 'unemploy\\_16'\n",
       "\\item 'unemploy\\_20to64'\n",
       "\\item 'employ\\_20to64'\n",
       "\\item 'employ\\_rename\\_20to64'\n",
       "\\item 'hsorhigher'\n",
       "\\item 'bach\\_orhigher'\n",
       "\\item 'less9thgrade'\n",
       "\\item 'grade9to12'\n",
       "\\item 'highschool'\n",
       "\\item 'somecollege'\n",
       "\\item 'assoc'\n",
       "\\item 'bachelors'\n",
       "\\item 'grad'\n",
       "\\item 'outcome\\_voted'\n",
       "\\item 'treatment\\_dum'\n",
       "\\item 'treat\\_hawthorne'\n",
       "\\item 'treat\\_civic'\n",
       "\\item 'treat\\_neighbors'\n",
       "\\item 'treat\\_self'\n",
       "\\item 'randn'\n",
       "\\item 'oneperhh'\n",
       "\\item 'p2004'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'sex'\n",
       "2. 'yob'\n",
       "3. 'g2000'\n",
       "4. 'g2002'\n",
       "5. 'g2004'\n",
       "6. 'p2000'\n",
       "7. 'p2002'\n",
       "8. 'cluster'\n",
       "9. 'votedav'\n",
       "10. 'dem'\n",
       "11. 'nov'\n",
       "12. 'aug'\n",
       "13. 'city'\n",
       "14. 'hh_id'\n",
       "15. 'hh_size'\n",
       "16. 'totalpopulation_estimate'\n",
       "17. 'percent_male'\n",
       "18. 'percent_female'\n",
       "19. 'median_age'\n",
       "20. 'percent_under5years'\n",
       "21. 'percent_5to9years'\n",
       "22. 'percent_10to14years'\n",
       "23. 'percent_15to19years'\n",
       "24. 'percent_20to24years'\n",
       "25. 'percent_25to34years'\n",
       "26. 'percent_35to44years'\n",
       "27. 'percent_45to54years'\n",
       "28. 'percent_55to59years'\n",
       "29. 'percent_60to64years'\n",
       "30. 'percent_65to74years'\n",
       "31. 'percent_75to84years'\n",
       "32. 'percent_85yearsandolder'\n",
       "33. 'percent_18yearsandolder'\n",
       "34. 'percent_21yearsandover'\n",
       "35. 'percent_62yearsandover'\n",
       "36. 'percent_65yearsandover'\n",
       "37. 'percent_white'\n",
       "38. 'percent_black'\n",
       "39. 'percent_amindian_alaskan'\n",
       "40. 'percent_asian'\n",
       "41. 'percent_nativeandother'\n",
       "42. 'percent_other_nativeandother'\n",
       "43. 'percent_hispanicorlatino'\n",
       "44. 'percent_race_other'\n",
       "45. 'median_income'\n",
       "46. 'mean_income'\n",
       "47. 'employ_16'\n",
       "48. 'unemploy_16'\n",
       "49. 'unemploy_20to64'\n",
       "50. 'employ_20to64'\n",
       "51. 'employ_rename_20to64'\n",
       "52. 'hsorhigher'\n",
       "53. 'bach_orhigher'\n",
       "54. 'less9thgrade'\n",
       "55. 'grade9to12'\n",
       "56. 'highschool'\n",
       "57. 'somecollege'\n",
       "58. 'assoc'\n",
       "59. 'bachelors'\n",
       "60. 'grad'\n",
       "61. 'outcome_voted'\n",
       "62. 'treatment_dum'\n",
       "63. 'treat_hawthorne'\n",
       "64. 'treat_civic'\n",
       "65. 'treat_neighbors'\n",
       "66. 'treat_self'\n",
       "67. 'randn'\n",
       "68. 'oneperhh'\n",
       "69. 'p2004'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"sex\"                          \"yob\"                         \n",
       " [3] \"g2000\"                        \"g2002\"                       \n",
       " [5] \"g2004\"                        \"p2000\"                       \n",
       " [7] \"p2002\"                        \"cluster\"                     \n",
       " [9] \"votedav\"                      \"dem\"                         \n",
       "[11] \"nov\"                          \"aug\"                         \n",
       "[13] \"city\"                         \"hh_id\"                       \n",
       "[15] \"hh_size\"                      \"totalpopulation_estimate\"    \n",
       "[17] \"percent_male\"                 \"percent_female\"              \n",
       "[19] \"median_age\"                   \"percent_under5years\"         \n",
       "[21] \"percent_5to9years\"            \"percent_10to14years\"         \n",
       "[23] \"percent_15to19years\"          \"percent_20to24years\"         \n",
       "[25] \"percent_25to34years\"          \"percent_35to44years\"         \n",
       "[27] \"percent_45to54years\"          \"percent_55to59years\"         \n",
       "[29] \"percent_60to64years\"          \"percent_65to74years\"         \n",
       "[31] \"percent_75to84years\"          \"percent_85yearsandolder\"     \n",
       "[33] \"percent_18yearsandolder\"      \"percent_21yearsandover\"      \n",
       "[35] \"percent_62yearsandover\"       \"percent_65yearsandover\"      \n",
       "[37] \"percent_white\"                \"percent_black\"               \n",
       "[39] \"percent_amindian_alaskan\"     \"percent_asian\"               \n",
       "[41] \"percent_nativeandother\"       \"percent_other_nativeandother\"\n",
       "[43] \"percent_hispanicorlatino\"     \"percent_race_other\"          \n",
       "[45] \"median_income\"                \"mean_income\"                 \n",
       "[47] \"employ_16\"                    \"unemploy_16\"                 \n",
       "[49] \"unemploy_20to64\"              \"employ_20to64\"               \n",
       "[51] \"employ_rename_20to64\"         \"hsorhigher\"                  \n",
       "[53] \"bach_orhigher\"                \"less9thgrade\"                \n",
       "[55] \"grade9to12\"                   \"highschool\"                  \n",
       "[57] \"somecollege\"                  \"assoc\"                       \n",
       "[59] \"bachelors\"                    \"grad\"                        \n",
       "[61] \"outcome_voted\"                \"treatment_dum\"               \n",
       "[63] \"treat_hawthorne\"              \"treat_civic\"                 \n",
       "[65] \"treat_neighbors\"              \"treat_self\"                  \n",
       "[67] \"randn\"                        \"oneperhh\"                    \n",
       "[69] \"p2004\"                       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colnames(social)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fb55af1-514f-4200-bc44-9f9360af8d22",
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1653562467707,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "3fb55af1-514f-4200-bc44-9f9360af8d22"
   },
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "noise.covars <- matrix(data = runif(nrow(social) * 13), \n",
    "                       nrow = nrow(social), ncol = 13)\n",
    "noise.covars <- data.frame(noise.covars)\n",
    "names(noise.covars) <- c(\"noise1\", \"noise2\", \"noise3\", \"noise4\", \"noise5\", \"noise6\",\n",
    "                         \"noise7\", \"noise8\", \"noise9\", \"noise10\", \"noise11\", \"noise12\",\"noise13\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8a3c6f9-acfa-4590-be81-717f60c395fe",
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1653562467708,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "f8a3c6f9-acfa-4590-be81-717f60c395fe"
   },
   "outputs": [],
   "source": [
    "working <- cbind(social, noise.covars)\n",
    "\n",
    "set.seed(333)\n",
    "#working <-  working[sample(nrow(social), 20000), ]\n",
    "\n",
    "# Pick a selection of covariates\n",
    "# If we have a lot of data and computation power, it is suggested that\n",
    "# we include all covariates and use regularization. This suggestion is\n",
    "# based on the observation that it's much easier to fix the overfitting \n",
    "# problem than to fix the underfitting problem.\n",
    "covariate.names <- c(\"yob\", \"hh_size\", \"sex\", \"city\", \"g2000\",\"g2002\", \"p2000\", \"p2002\", \"p2004\"\n",
    "                     ,\"totalpopulation_estimate\",\"percent_male\",\"median_age\", \"percent_62yearsandover\"\n",
    "                     ,\"percent_white\", \"percent_black\", \"median_income\",\n",
    "                     \"employ_20to64\", \"highschool\", \"bach_orhigher\",\"percent_hispanicorlatino\",\n",
    "                     \"noise1\", \"noise2\", \"noise3\", \"noise4\", \"noise5\", \"noise6\",\n",
    "                     \"noise7\", \"noise8\", \"noise9\", \"noise10\", \"noise11\", \"noise12\",\"noise13\")\n",
    "\n",
    "\n",
    "names(working)[names(working)==\"outcome_voted\"] <- \"Y\"\n",
    "Y <- working[[\"Y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bc8c9f5-3d2f-4871-a6d2-0a394b79644c",
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1653562467708,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "1bc8c9f5-3d2f-4871-a6d2-0a394b79644c"
   },
   "outputs": [],
   "source": [
    "names(working)[names(working)==\"treat_neighbors\"] <- \"W\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f218e623-146f-4ea3-bdf8-ec2723ca9bb2",
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1653562467709,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "f218e623-146f-4ea3-bdf8-ec2723ca9bb2"
   },
   "outputs": [],
   "source": [
    "W <- working[[\"W\"]]\n",
    "covariates <- working[covariate.names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "835dad57-ab38-4d04-9956-c1f529644fd2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1653562467712,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "835dad57-ab38-4d04-9956-c1f529644fd2",
    "outputId": "263bd6d4-9a63-4a9b-e043-a2402fa14e9e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'yob'</li><li>'hh_size'</li><li>'sex'</li><li>'city'</li><li>'g2000'</li><li>'g2002'</li><li>'p2000'</li><li>'p2002'</li><li>'p2004'</li><li>'totalpopulation_estimate'</li><li>'percent_male'</li><li>'median_age'</li><li>'percent_62yearsandover'</li><li>'percent_white'</li><li>'percent_black'</li><li>'median_income'</li><li>'employ_20to64'</li><li>'highschool'</li><li>'bach_orhigher'</li><li>'percent_hispanicorlatino'</li><li>'noise1'</li><li>'noise2'</li><li>'noise3'</li><li>'noise4'</li><li>'noise5'</li><li>'noise6'</li><li>'noise7'</li><li>'noise8'</li><li>'noise9'</li><li>'noise10'</li><li>'noise11'</li><li>'noise12'</li><li>'noise13'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'yob'\n",
       "\\item 'hh\\_size'\n",
       "\\item 'sex'\n",
       "\\item 'city'\n",
       "\\item 'g2000'\n",
       "\\item 'g2002'\n",
       "\\item 'p2000'\n",
       "\\item 'p2002'\n",
       "\\item 'p2004'\n",
       "\\item 'totalpopulation\\_estimate'\n",
       "\\item 'percent\\_male'\n",
       "\\item 'median\\_age'\n",
       "\\item 'percent\\_62yearsandover'\n",
       "\\item 'percent\\_white'\n",
       "\\item 'percent\\_black'\n",
       "\\item 'median\\_income'\n",
       "\\item 'employ\\_20to64'\n",
       "\\item 'highschool'\n",
       "\\item 'bach\\_orhigher'\n",
       "\\item 'percent\\_hispanicorlatino'\n",
       "\\item 'noise1'\n",
       "\\item 'noise2'\n",
       "\\item 'noise3'\n",
       "\\item 'noise4'\n",
       "\\item 'noise5'\n",
       "\\item 'noise6'\n",
       "\\item 'noise7'\n",
       "\\item 'noise8'\n",
       "\\item 'noise9'\n",
       "\\item 'noise10'\n",
       "\\item 'noise11'\n",
       "\\item 'noise12'\n",
       "\\item 'noise13'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'yob'\n",
       "2. 'hh_size'\n",
       "3. 'sex'\n",
       "4. 'city'\n",
       "5. 'g2000'\n",
       "6. 'g2002'\n",
       "7. 'p2000'\n",
       "8. 'p2002'\n",
       "9. 'p2004'\n",
       "10. 'totalpopulation_estimate'\n",
       "11. 'percent_male'\n",
       "12. 'median_age'\n",
       "13. 'percent_62yearsandover'\n",
       "14. 'percent_white'\n",
       "15. 'percent_black'\n",
       "16. 'median_income'\n",
       "17. 'employ_20to64'\n",
       "18. 'highschool'\n",
       "19. 'bach_orhigher'\n",
       "20. 'percent_hispanicorlatino'\n",
       "21. 'noise1'\n",
       "22. 'noise2'\n",
       "23. 'noise3'\n",
       "24. 'noise4'\n",
       "25. 'noise5'\n",
       "26. 'noise6'\n",
       "27. 'noise7'\n",
       "28. 'noise8'\n",
       "29. 'noise9'\n",
       "30. 'noise10'\n",
       "31. 'noise11'\n",
       "32. 'noise12'\n",
       "33. 'noise13'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"yob\"                      \"hh_size\"                 \n",
       " [3] \"sex\"                      \"city\"                    \n",
       " [5] \"g2000\"                    \"g2002\"                   \n",
       " [7] \"p2000\"                    \"p2002\"                   \n",
       " [9] \"p2004\"                    \"totalpopulation_estimate\"\n",
       "[11] \"percent_male\"             \"median_age\"              \n",
       "[13] \"percent_62yearsandover\"   \"percent_white\"           \n",
       "[15] \"percent_black\"            \"median_income\"           \n",
       "[17] \"employ_20to64\"            \"highschool\"              \n",
       "[19] \"bach_orhigher\"            \"percent_hispanicorlatino\"\n",
       "[21] \"noise1\"                   \"noise2\"                  \n",
       "[23] \"noise3\"                   \"noise4\"                  \n",
       "[25] \"noise5\"                   \"noise6\"                  \n",
       "[27] \"noise7\"                   \"noise8\"                  \n",
       "[29] \"noise9\"                   \"noise10\"                 \n",
       "[31] \"noise11\"                  \"noise12\"                 \n",
       "[33] \"noise13\"                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(covariates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6727ad3-ef4b-4f05-ad23-5a724edfad6e",
   "metadata": {
    "id": "e6727ad3-ef4b-4f05-ad23-5a724edfad6e"
   },
   "source": [
    "Algunos algoritmos necesitan que las covariables sean escaladas para que funcionen mejor. En este caso vamos a usar la función \"scale\" para hacerlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6c5a608-e69d-4e16-9cf4-919e72e9f78a",
   "metadata": {
    "executionInfo": {
     "elapsed": 692,
     "status": "ok",
     "timestamp": 1653562468380,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "e6c5a608-e69d-4e16-9cf4-919e72e9f78a"
   },
   "outputs": [],
   "source": [
    "# some algorithms require our covariates be scaled\n",
    "# scale, with default settings, will calculate the mean and standard deviation of the entire vector, \n",
    "# then \"scale\" each element by those values by subtracting the mean and dividing by the sd\n",
    "covariates.scaled <- scale(covariates)\n",
    "processed.unscaled <- data.frame(Y, W, covariates)\n",
    "processed.scaled <- data.frame(Y, W, covariates.scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0c4194-da74-411f-890d-f8ac12298c3c",
   "metadata": {
    "id": "af0c4194-da74-411f-890d-f8ac12298c3c"
   },
   "source": [
    "El objetivo principal de machine learning es la predicción fuera de la muestra, es por eso que lo que se hace habitualmente para simularlo es partir la muestra de datos en dos, una muestra de entrenamiento y la otra de testeo. Incluso se suele dividir en tres también, lo que sería entrenamiento, validación y testeo. Para partir los datos usamos la función \"sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c2a3c61-f6f7-421a-b4c2-9c8c47d5ba56",
   "metadata": {
    "executionInfo": {
     "elapsed": 95,
     "status": "ok",
     "timestamp": 1653562468382,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "3c2a3c61-f6f7-421a-b4c2-9c8c47d5ba56"
   },
   "outputs": [],
   "source": [
    "# Creemos una función que nos devuelvo dos bd\n",
    "\n",
    "train_test <- function(bd, porcentaje) {\n",
    "    train <- sample(nrow(bd), round(nrow(bd)*porcentaje), replace = FALSE)\n",
    "    train.bd <- bd[train,]\n",
    "    test.bd <- bd[-train,]\n",
    "    return(list(train.bd,test.bd))\n",
    "    }\n",
    "\n",
    "set.seed(45)\n",
    "lista_train_test <- train_test(processed.scaled, 0.9)\n",
    "y.train <- as.matrix(lista_train_test[[1]]$Y, ncol = 1)\n",
    "y.test <- as.matrix(lista_train_test[[2]]$Y, ncol = 1)\n",
    "X.train <- lista_train_test[[1]]\n",
    "X.test <- lista_train_test[[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f8e4d7-607b-4fb4-9c46-c751605ea844",
   "metadata": {
    "id": "08f8e4d7-607b-4fb4-9c46-c751605ea844"
   },
   "source": [
    "Creamos las formulas que vamos a trabajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59196eee-a959-4928-b83e-323e34573590",
   "metadata": {
    "executionInfo": {
     "elapsed": 95,
     "status": "ok",
     "timestamp": 1653562468384,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "59196eee-a959-4928-b83e-323e34573590"
   },
   "outputs": [],
   "source": [
    "sumx <- paste(covariate.names, collapse = \" + \")  # \"X1 + X2 + X3 + ...\" for substitution later\n",
    "interx <- paste(\" (\",sumx, \")^2\", sep=\"\")  # \"(X1 + X2 + X3 + ...)^2\" for substitution later\n",
    "linear <- paste(\"Y\", sumx, sep = \"~\")\n",
    "linear <- as.formula(linear)\n",
    "linear.inter <- (paste(\"Y\", interx, sep = \"~\"))\n",
    "linear.inter <- as.formula(linear.inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04a557-8de4-4718-a3a9-b432e81c17a4",
   "metadata": {
    "id": "fd04a557-8de4-4718-a3a9-b432e81c17a4"
   },
   "source": [
    "## Modelos lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb313729-a38e-42ab-83b9-258387c31427",
   "metadata": {
    "id": "fb313729-a38e-42ab-83b9-258387c31427"
   },
   "source": [
    "### Mínimos cuadrados ordinarios\n",
    "\n",
    "Cuándo hablamos de modelos lineales para predicción estamos suponiendo que la función $E(Y|X)$ es lineal en las entradas $X_1,...,X_p$. Por lo tanto podemos tomar un vector $X^T=(X_1,...,X_p)$ y predecir $y$ con la siguiente función:\n",
    "\n",
    "\\begin{equation}\n",
    "f(X)=\\beta_{0}+\\sum_{j=1}^{p}\\boldsymbol{X}_{j}\\beta_{j}\n",
    "\\end{equation}\n",
    "\n",
    "En esta ecuación los parámetros $\\beta_j$ son desconocidos y $\\boldsymbol{X}$ es una matriz de datos conocidos.\n",
    "EL objetivo es estimar los coeficientes $\\beta=\\left(\\beta_0,\\beta_1,...,beta_p\\right)^T, para esto, el método mas popular es el de mínimos cuadrados el cual tiene como objetivo reducir la suma de cuadrados de los residuos.\n",
    "\n",
    "\\begin{equation}\n",
    "RSS\\left(\\beta\\right) = \\sum_{i=1}^{N}\\left(y_i-\\sum_{j=0}^{p}x_{ij}\\beta_j\\right)^2\n",
    "\\end{equation}\n",
    "\n",
    "Para minimizarla podemos escrbirla de la siguiente forma:\n",
    "\n",
    "\\begin{equation}\n",
    "RSS\\left(\\beta\\right) = \\left(\\boldsymbol{y}-\\boldsymbol{X}\\beta\\right)^T\\left(\\boldsymbol{y}-\\boldsymbol{X}\\beta\\right)\n",
    "\\end{equation}\n",
    "\n",
    "luego derivando e igualando a 0 tenemos:\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{X}^T\\boldsymbol{y}-\\boldsymbol{X}^T\\boldsymbol{X}\\beta = 0\n",
    "\\end{equation}\n",
    "\n",
    "Asumiendo que $\\boldsymbol{X}$ tiene rango completo de columnas podemos encontrar una única solución dada por:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\beta} = \\left(\\boldsymbol{X}^T\\boldsymbol{X}\\right)^{-1}\\boldsymbol{X}^T\\boldsymbol{y}\n",
    "\\end{equation}\n",
    "\n",
    "Una condición necesaria para aplicar esta estimación es que las columnas de $\\boldsymbol{X}$ sean independientes entre sí, en otro caso no tendríamos rango completo de columna. La función *lm* de R elimina aquellas columnas redundantes de la estimación y lo calcula, la mayoría de los software estadísticos lo hacen, pero no ocurre así si quisieramos aplicar este cálculo por nuestra cuenta.\n",
    "\n",
    "Como se mencionó la función *lm* es el comando para calcular mínimos cuadrados en R. Los parámetros básicos para calcularla son una fórmula del objeto de tipo *\"formula\"* de R el cuál deberá tener cuál es la variable dependiente y cuales son las variables explicativas y la base de datos de dónde sale dicha información.\n",
    "\n",
    "Procedemos a ver un ejemplo con los datos de social.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcef3ee2-c7c7-4f4f-a05f-d48e40125de9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 94,
     "status": "ok",
     "timestamp": 1653562468385,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "fcef3ee2-c7c7-4f4f-a05f-d48e40125de9",
    "outputId": "606cd982-b3c4-44d6-913f-14bd92562a55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y ~ yob + hh_size + sex + city + g2000 + g2002 + p2000 + p2002 + \n",
       "    p2004 + totalpopulation_estimate + percent_male + median_age + \n",
       "    percent_62yearsandover + percent_white + percent_black + \n",
       "    median_income + employ_20to64 + highschool + bach_orhigher + \n",
       "    percent_hispanicorlatino + noise1 + noise2 + noise3 + noise4 + \n",
       "    noise5 + noise6 + noise7 + noise8 + noise9 + noise10 + noise11 + \n",
       "    noise12 + noise13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# la fórmula es\n",
    "linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6554e085-ec1a-45c0-9bf4-021f80b6187e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 88,
     "status": "ok",
     "timestamp": 1653562468385,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "6554e085-ec1a-45c0-9bf4-021f80b6187e",
    "outputId": "72ebc251-bbc9-49fd-aa35-a9a5efe400ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = linear, data = processed.scaled)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-0.7798 -0.3387 -0.2182  0.5444  1.0269 \n",
       "\n",
       "Coefficients:\n",
       "                           Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)               0.3183027  0.0012972 245.378  < 2e-16 ***\n",
       "yob                      -0.0298619  0.0014321 -20.851  < 2e-16 ***\n",
       "hh_size                   0.0079806  0.0013736   5.810 6.27e-09 ***\n",
       "sex                      -0.0041355  0.0012990  -3.184  0.00145 ** \n",
       "city                      0.0425474  0.0013905  30.599  < 2e-16 ***\n",
       "g2000                    -0.0098765  0.0014243  -6.934 4.11e-12 ***\n",
       "g2002                     0.0293672  0.0014239  20.625  < 2e-16 ***\n",
       "p2000                     0.0377639  0.0013333  28.324  < 2e-16 ***\n",
       "p2002                     0.0576975  0.0013488  42.777  < 2e-16 ***\n",
       "p2004                     0.0756268  0.0013289  56.911  < 2e-16 ***\n",
       "totalpopulation_estimate  0.0103734  0.0016749   6.193 5.90e-10 ***\n",
       "percent_male             -0.0041805  0.0015556  -2.687  0.00720 ** \n",
       "median_age                0.0031203  0.0031385   0.994  0.32013    \n",
       "percent_62yearsandover    0.0059074  0.0030900   1.912  0.05591 .  \n",
       "percent_white             0.0191745  0.0033847   5.665 1.47e-08 ***\n",
       "percent_black             0.0182028  0.0030556   5.957 2.57e-09 ***\n",
       "median_income             0.0252945  0.0029970   8.440  < 2e-16 ***\n",
       "employ_20to64            -0.0116287  0.0018411  -6.316 2.69e-10 ***\n",
       "highschool                0.0321456  0.0047126   6.821 9.07e-12 ***\n",
       "bach_orhigher             0.0093469  0.0051422   1.818  0.06911 .  \n",
       "percent_hispanicorlatino  0.0016305  0.0017551   0.929  0.35291    \n",
       "noise1                   -0.0005721  0.0012974  -0.441  0.65925    \n",
       "noise2                    0.0008281  0.0012974   0.638  0.52327    \n",
       "noise3                   -0.0023713  0.0012973  -1.828  0.06758 .  \n",
       "noise4                   -0.0019993  0.0012974  -1.541  0.12332    \n",
       "noise5                   -0.0010014  0.0012974  -0.772  0.44021    \n",
       "noise6                    0.0023886  0.0012973   1.841  0.06559 .  \n",
       "noise7                    0.0003999  0.0012974   0.308  0.75791    \n",
       "noise8                    0.0006979  0.0012973   0.538  0.59061    \n",
       "noise9                   -0.0004706  0.0012974  -0.363  0.71677    \n",
       "noise10                   0.0009529  0.0012974   0.734  0.46266    \n",
       "noise11                   0.0007511  0.0012973   0.579  0.56261    \n",
       "noise12                   0.0003130  0.0012974   0.241  0.80937    \n",
       "noise13                   0.0017338  0.0012974   1.336  0.18141    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.4494 on 119965 degrees of freedom\n",
       "Multiple R-squared:  0.06968,\tAdjusted R-squared:  0.06943 \n",
       "F-statistic: 272.3 on 33 and 119965 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ols <- lm(linear, processed.scaled)\n",
    "summary(ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66dbc11-467a-4829-9c94-8dc62269af6f",
   "metadata": {
    "id": "a66dbc11-467a-4829-9c94-8dc62269af6f"
   },
   "source": [
    "Como se puede ver, el método de mínimos cuadrados considera a los ruidos que agregamos nosotros como significativos, por lo tanto no tiene la capacidad de detectar que es ruido, simplemente las ajusta junto a todas las otras. Esto agrega otro supuesto más a MCO que tenemos que tener en cuenta, que es que tenemos que tener bien especificado el modelo, o sea todas las variables que pasamos como explicativas deben ser realmente las variables que explican a $y$. Esto es particularmente dificil en los casos reales, y la idea es tratar de encontrar las variables que explican el modelo a través de métodos de selección de variables, los cuales nos deberían acercar a la verdadera función.\n",
    "\n",
    "De todas formas, si el método predice bien podemos tomarlo aunque tenga variables ruidosas, el objetivo acá es la predicción. Para chequear que tan bueno es un método para predcir por lo general se usa lo de partir la base de datos en dos, una grande que sirve para los datos de entrenamiento y otra más pequeña para el testeo. La idea es la predicción por fuera de la muestra. Luego con los coeficientes calculados con los datos de entrenamiento se predice sobre la base de prueba y se mide que tan efectivo es con alguna métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a6c65af-62cf-4657-b516-0fba01d48e14",
   "metadata": {
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1653562468389,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "7a6c65af-62cf-4657-b516-0fba01d48e14"
   },
   "outputs": [],
   "source": [
    "ols <- lm(linear, data = X.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c232177-d18a-412b-ac35-a1d34ec174f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1653562468390,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "0c232177-d18a-412b-ac35-a1d34ec174f5",
    "outputId": "44e2980d-6f49-4a07-b22c-43b62882af95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = linear, data = X.train)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-0.7801 -0.3387 -0.2187  0.5445  1.0288 \n",
       "\n",
       "Coefficients:\n",
       "                           Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)               0.3183863  0.0013677 232.794  < 2e-16 ***\n",
       "yob                      -0.0285834  0.0015083 -18.951  < 2e-16 ***\n",
       "hh_size                   0.0076376  0.0014473   5.277 1.32e-07 ***\n",
       "sex                      -0.0044537  0.0013695  -3.252  0.00115 ** \n",
       "city                      0.0435412  0.0014667  29.686  < 2e-16 ***\n",
       "g2000                    -0.0094400  0.0015004  -6.292 3.15e-10 ***\n",
       "g2002                     0.0297059  0.0015024  19.773  < 2e-16 ***\n",
       "p2000                     0.0377601  0.0014057  26.862  < 2e-16 ***\n",
       "p2002                     0.0570572  0.0014225  40.111  < 2e-16 ***\n",
       "p2004                     0.0754573  0.0014011  53.857  < 2e-16 ***\n",
       "totalpopulation_estimate  0.0114049  0.0017666   6.456 1.08e-10 ***\n",
       "percent_male             -0.0042304  0.0016430  -2.575  0.01003 *  \n",
       "median_age                0.0026059  0.0033086   0.788  0.43092    \n",
       "percent_62yearsandover    0.0067227  0.0032557   2.065  0.03893 *  \n",
       "percent_white             0.0201861  0.0035641   5.664 1.49e-08 ***\n",
       "percent_black             0.0185346  0.0032166   5.762 8.33e-09 ***\n",
       "median_income             0.0258173  0.0031589   8.173 3.04e-16 ***\n",
       "employ_20to64            -0.0134757  0.0019389  -6.950 3.66e-12 ***\n",
       "highschool                0.0307212  0.0049669   6.185 6.23e-10 ***\n",
       "bach_orhigher             0.0079973  0.0054201   1.475  0.14009    \n",
       "percent_hispanicorlatino  0.0014896  0.0018534   0.804  0.42155    \n",
       "noise1                   -0.0003105  0.0013678  -0.227  0.82041    \n",
       "noise2                    0.0005860  0.0013673   0.429  0.66822    \n",
       "noise3                   -0.0025405  0.0013684  -1.857  0.06338 .  \n",
       "noise4                   -0.0023549  0.0013678  -1.722  0.08515 .  \n",
       "noise5                   -0.0009239  0.0013670  -0.676  0.49910    \n",
       "noise6                    0.0024385  0.0013674   1.783  0.07455 .  \n",
       "noise7                    0.0005021  0.0013673   0.367  0.71347    \n",
       "noise8                    0.0012082  0.0013679   0.883  0.37713    \n",
       "noise9                   -0.0004681  0.0013674  -0.342  0.73211    \n",
       "noise10                   0.0009881  0.0013679   0.722  0.47007    \n",
       "noise11                   0.0003758  0.0013678   0.275  0.78353    \n",
       "noise12                  -0.0001798  0.0013674  -0.131  0.89538    \n",
       "noise13                   0.0011741  0.0013665   0.859  0.39024    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.4495 on 107965 degrees of freedom\n",
       "Multiple R-squared:  0.06963,\tAdjusted R-squared:  0.06934 \n",
       "F-statistic: 244.8 on 33 and 107965 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(ols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241c49d4-ddf9-45b3-8a7f-8dcffafcc619",
   "metadata": {
    "id": "241c49d4-ddf9-45b3-8a7f-8dcffafcc619"
   },
   "source": [
    "Una forma de medir la efectividad del método para predecir es utilizando el error cuadrático medio, existen varias más, el error abosluto medio, el error logarítmico cuadrado medo, etc. Estos son los utilizados para medir la efectividad de las regresiones.\n",
    "\n",
    "En R no están de manera predeterminada por lo tanto procedemos a armarlos con una función nosotros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c733f7d-3e35-44c7-a284-70609a1d3be6",
   "metadata": {
    "executionInfo": {
     "elapsed": 85,
     "status": "ok",
     "timestamp": 1653562468390,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "8c733f7d-3e35-44c7-a284-70609a1d3be6"
   },
   "outputs": [],
   "source": [
    "mse <- function(pred, y_test){\n",
    "    return((mean((pred-y_test)^2)))\n",
    "    }   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49032c4-4900-49c0-86a9-637ecc032616",
   "metadata": {
    "id": "e49032c4-4900-49c0-86a9-637ecc032616"
   },
   "source": [
    "La función *predcit* en R es una función genérica que se puede aplicar a distintos objetos, solo que depende cual sea recibe parámetros distintos. Esto es parte de lo que se denomina *polimorfismo* en la programación orientada a objeto.\n",
    "\n",
    "Es por eso que la hay que calcular las predicciones primero y luego calcular la métrica. Como se puede ver el primer número que es sobre la base de test, es mayor que sobre la base de entrenamiento, aunque son bastantes similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a412df8-13ae-4fbf-806d-c9982a080015",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 85,
     "status": "ok",
     "timestamp": 1653562468391,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "5a412df8-13ae-4fbf-806d-c9982a080015",
    "outputId": "ffd74408-4e8c-4b07-cdb4-a6128bb5150a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>mse_train</dt><dd>0.201945471512763</dd><dt>mse_test</dt><dd>0.201219570688055</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[mse\\textbackslash{}\\_train] 0.201945471512763\n",
       "\\item[mse\\textbackslash{}\\_test] 0.201219570688055\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "mse_train\n",
       ":   0.201945471512763mse_test\n",
       ":   0.201219570688055\n",
       "\n"
      ],
      "text/plain": [
       "mse_train  mse_test \n",
       "0.2019455 0.2012196 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ols_pred <- predict(ols, X.test)\n",
    "ols_rdos <- c( mse_train = mse(predict(ols, X.train), y.train),mse_test = mse(ols_pred, y.test))\n",
    "ols_rdos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa5d58a-6df3-4f1e-91fc-39c0923abecb",
   "metadata": {
    "id": "7aa5d58a-6df3-4f1e-91fc-39c0923abecb"
   },
   "source": [
    "Esta son las métricas para evaluar una regresión, pero en nuestro ejemplo la variable respuesta es una variable binomial, por lo tanto es un problema de clasificación y no de regresión. Existen otro tipo de métricas para poder evaluar un método de estimación cuando el problema es de predicción, entre ellos los más conocidos son **precision** y **recall**. Para observar esto miremos lo que se conoce como matriz de confusión.\n",
    "\n",
    "![image.png](attachment:0818f836-dd79-4170-bae3-a750d5515cb2.png)\n",
    "\n",
    "Entonces la precision o valor predictivo positivo  va medir a todos aquellos a los que predecimos como positivos y es verdad (verdaderos positivos) sobre todos los que predecimos como verdaderos. Más formal $VP/(VP+FP)$.\n",
    "\n",
    "El recall o sensibilidad va medir a todos los verdaderos positivos sobre todos los que son positivos realmente. Más formal $VP/(VP+FN)$\n",
    "\n",
    "La especificidad o razon de verdaders negativos mide todos aquellos que son verdaderos negativos sobre todos los negativos reales. Más formal $VN/(FP+VN)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4fdec6-31df-490b-8917-143ea489bb1d",
   "metadata": {
    "id": "ce4fdec6-31df-490b-8917-143ea489bb1d"
   },
   "source": [
    "Estos indicadores deben estar balanceados entre sí, no se puede intentar mejorar solo uno. Por ejemplo si aumentamos la precisión llevandola a 1, significa que acertamos a todos los que son verdaderamente positivos, pero esto, probablemente traiga aparejada que tenemos muchos falsos positivos también, por lo tanto puede ser indicio de sobre ajuste (*overfitting*). En cambio si mejoramos el recall, procurando no tener falsos negativos, puede dar indicios de sub-ajuste (*underfittinh*). \n",
    "\n",
    "Existe unfa fórmula que los unifica a la precision y al recall para trabajar de manera unificada, estos se conocen como las medidas $F_1$. En este caso la fórmula es la siguiente:\n",
    "\\begin{equation}\n",
    "F_1 = \\frac{2}{1/prec+1/rec}\n",
    "\\end{equation}\n",
    "\n",
    "Este indicador va de 0 a 1 siendo 1 el mejor resultado.\n",
    "\n",
    "Estos indicadores no se encuentran en R pero también son fáciles de calcular con una función propia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "684243f8-ecd1-4039-8490-6c1c79aeaa39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 85,
     "status": "ok",
     "timestamp": 1653562468393,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "684243f8-ecd1-4039-8490-6c1c79aeaa39",
    "outputId": "c8923ceb-4e47-413e-c585-062f025103c0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>...</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item ...\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 0\n",
       "3. 0\n",
       "4. 0\n",
       "5. 0\n",
       "6. 0\n",
       "7. 0\n",
       "8. 1\n",
       "9. 0\n",
       "10. 0\n",
       "11. 0\n",
       "12. 0\n",
       "13. 0\n",
       "14. 1\n",
       "15. 0\n",
       "16. 0\n",
       "17. 0\n",
       "18. 0\n",
       "19. 0\n",
       "20. 0\n",
       "21. 0\n",
       "22. 0\n",
       "23. 0\n",
       "24. 0\n",
       "25. 0\n",
       "26. 0\n",
       "27. 0\n",
       "28. 0\n",
       "29. 1\n",
       "30. 0\n",
       "31. 0\n",
       "32. 0\n",
       "33. 0\n",
       "34. 0\n",
       "35. 0\n",
       "36. 0\n",
       "37. 0\n",
       "38. 0\n",
       "39. 1\n",
       "40. 0\n",
       "41. 0\n",
       "42. 0\n",
       "43. 0\n",
       "44. 0\n",
       "45. 0\n",
       "46. 0\n",
       "47. 0\n",
       "48. 0\n",
       "49. 1\n",
       "50. 0\n",
       "51. 0\n",
       "52. 0\n",
       "53. 0\n",
       "54. 0\n",
       "55. 0\n",
       "56. 0\n",
       "57. 0\n",
       "58. 0\n",
       "59. 0\n",
       "60. 0\n",
       "61. 0\n",
       "62. 0\n",
       "63. 1\n",
       "64. 0\n",
       "65. 0\n",
       "66. 1\n",
       "67. 1\n",
       "68. 0\n",
       "69. 0\n",
       "70. 0\n",
       "71. 0\n",
       "72. 0\n",
       "73. 0\n",
       "74. 0\n",
       "75. 0\n",
       "76. 1\n",
       "77. 0\n",
       "78. 0\n",
       "79. 0\n",
       "80. 0\n",
       "81. 0\n",
       "82. 0\n",
       "83. 0\n",
       "84. 0\n",
       "85. 0\n",
       "86. 1\n",
       "87. 0\n",
       "88. 0\n",
       "89. 0\n",
       "90. 0\n",
       "91. 0\n",
       "92. 0\n",
       "93. 0\n",
       "94. 0\n",
       "95. 0\n",
       "96. 0\n",
       "97. 0\n",
       "98. 0\n",
       "99. 0\n",
       "100. 0\n",
       "101. 0\n",
       "102. 0\n",
       "103. 0\n",
       "104. 0\n",
       "105. 0\n",
       "106. 0\n",
       "107. 1\n",
       "108. 1\n",
       "109. 1\n",
       "110. 0\n",
       "111. 0\n",
       "112. 0\n",
       "113. 0\n",
       "114. 0\n",
       "115. 0\n",
       "116. 0\n",
       "117. 0\n",
       "118. 0\n",
       "119. 0\n",
       "120. 0\n",
       "121. 0\n",
       "122. 0\n",
       "123. 0\n",
       "124. 0\n",
       "125. 0\n",
       "126. 1\n",
       "127. 1\n",
       "128. 0\n",
       "129. 0\n",
       "130. 0\n",
       "131. 0\n",
       "132. 0\n",
       "133. 0\n",
       "134. 0\n",
       "135. 0\n",
       "136. 0\n",
       "137. 0\n",
       "138. 0\n",
       "139. 0\n",
       "140. 0\n",
       "141. 0\n",
       "142. 0\n",
       "143. 0\n",
       "144. 0\n",
       "145. 1\n",
       "146. 0\n",
       "147. 0\n",
       "148. 0\n",
       "149. 0\n",
       "150. 0\n",
       "151. 0\n",
       "152. 1\n",
       "153. 0\n",
       "154. 0\n",
       "155. 0\n",
       "156. 0\n",
       "157. 1\n",
       "158. 0\n",
       "159. 0\n",
       "160. 0\n",
       "161. 0\n",
       "162. 0\n",
       "163. 0\n",
       "164. 0\n",
       "165. 0\n",
       "166. 0\n",
       "167. 0\n",
       "168. 0\n",
       "169. 0\n",
       "170. 0\n",
       "171. 0\n",
       "172. 0\n",
       "173. 0\n",
       "174. 1\n",
       "175. 0\n",
       "176. 0\n",
       "177. 0\n",
       "178. 0\n",
       "179. 0\n",
       "180. 0\n",
       "181. 0\n",
       "182. 0\n",
       "183. 0\n",
       "184. 0\n",
       "185. 0\n",
       "186. 0\n",
       "187. 1\n",
       "188. 0\n",
       "189. 0\n",
       "190. 0\n",
       "191. 0\n",
       "192. 0\n",
       "193. 0\n",
       "194. 0\n",
       "195. 0\n",
       "196. 0\n",
       "197. 0\n",
       "198. 0\n",
       "199. 0\n",
       "200. 1\n",
       "201. ...\n",
       "202. 1\n",
       "203. 0\n",
       "204. 0\n",
       "205. 0\n",
       "206. 0\n",
       "207. 0\n",
       "208. 0\n",
       "209. 0\n",
       "210. 0\n",
       "211. 0\n",
       "212. 1\n",
       "213. 0\n",
       "214. 0\n",
       "215. 0\n",
       "216. 0\n",
       "217. 0\n",
       "218. 0\n",
       "219. 0\n",
       "220. 0\n",
       "221. 0\n",
       "222. 1\n",
       "223. 0\n",
       "224. 0\n",
       "225. 0\n",
       "226. 0\n",
       "227. 0\n",
       "228. 0\n",
       "229. 0\n",
       "230. 0\n",
       "231. 0\n",
       "232. 0\n",
       "233. 0\n",
       "234. 0\n",
       "235. 0\n",
       "236. 0\n",
       "237. 0\n",
       "238. 0\n",
       "239. 0\n",
       "240. 0\n",
       "241. 0\n",
       "242. 0\n",
       "243. 0\n",
       "244. 0\n",
       "245. 0\n",
       "246. 1\n",
       "247. 0\n",
       "248. 1\n",
       "249. 0\n",
       "250. 0\n",
       "251. 0\n",
       "252. 0\n",
       "253. 1\n",
       "254. 0\n",
       "255. 0\n",
       "256. 0\n",
       "257. 0\n",
       "258. 0\n",
       "259. 0\n",
       "260. 0\n",
       "261. 1\n",
       "262. 0\n",
       "263. 0\n",
       "264. 0\n",
       "265. 0\n",
       "266. 0\n",
       "267. 0\n",
       "268. 0\n",
       "269. 0\n",
       "270. 0\n",
       "271. 0\n",
       "272. 0\n",
       "273. 0\n",
       "274. 0\n",
       "275. 0\n",
       "276. 0\n",
       "277. 0\n",
       "278. 0\n",
       "279. 0\n",
       "280. 0\n",
       "281. 0\n",
       "282. 0\n",
       "283. 0\n",
       "284. 0\n",
       "285. 0\n",
       "286. 0\n",
       "287. 0\n",
       "288. 1\n",
       "289. 0\n",
       "290. 0\n",
       "291. 0\n",
       "292. 0\n",
       "293. 0\n",
       "294. 0\n",
       "295. 0\n",
       "296. 0\n",
       "297. 0\n",
       "298. 0\n",
       "299. 0\n",
       "300. 0\n",
       "301. 0\n",
       "302. 0\n",
       "303. 0\n",
       "304. 1\n",
       "305. 0\n",
       "306. 0\n",
       "307. 0\n",
       "308. 0\n",
       "309. 0\n",
       "310. 0\n",
       "311. 0\n",
       "312. 0\n",
       "313. 0\n",
       "314. 0\n",
       "315. 0\n",
       "316. 0\n",
       "317. 0\n",
       "318. 0\n",
       "319. 0\n",
       "320. 0\n",
       "321. 0\n",
       "322. 0\n",
       "323. 0\n",
       "324. 0\n",
       "325. 0\n",
       "326. 0\n",
       "327. 0\n",
       "328. 0\n",
       "329. 0\n",
       "330. 0\n",
       "331. 0\n",
       "332. 0\n",
       "333. 0\n",
       "334. 0\n",
       "335. 0\n",
       "336. 0\n",
       "337. 0\n",
       "338. 0\n",
       "339. 0\n",
       "340. 0\n",
       "341. 1\n",
       "342. 0\n",
       "343. 0\n",
       "344. 0\n",
       "345. 0\n",
       "346. 1\n",
       "347. 0\n",
       "348. 0\n",
       "349. 0\n",
       "350. 0\n",
       "351. 0\n",
       "352. 0\n",
       "353. 0\n",
       "354. 0\n",
       "355. 0\n",
       "356. 0\n",
       "357. 0\n",
       "358. 0\n",
       "359. 0\n",
       "360. 0\n",
       "361. 1\n",
       "362. 0\n",
       "363. 0\n",
       "364. 0\n",
       "365. 0\n",
       "366. 0\n",
       "367. 0\n",
       "368. 0\n",
       "369. 0\n",
       "370. 0\n",
       "371. 0\n",
       "372. 0\n",
       "373. 0\n",
       "374. 0\n",
       "375. 0\n",
       "376. 0\n",
       "377. 0\n",
       "378. 0\n",
       "379. 0\n",
       "380. 0\n",
       "381. 0\n",
       "382. 1\n",
       "383. 0\n",
       "384. 0\n",
       "385. 0\n",
       "386. 0\n",
       "387. 0\n",
       "388. 1\n",
       "389. 0\n",
       "390. 0\n",
       "391. 0\n",
       "392. 0\n",
       "393. 0\n",
       "394. 0\n",
       "395. 1\n",
       "396. 0\n",
       "397. 0\n",
       "398. 0\n",
       "399. 0\n",
       "400. 0\n",
       "401. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    [1] 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       "   [37] 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0\n",
       "   [73] 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
       "  [109] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [145] 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       "  [181] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [217] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [253] 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       "  [289] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       "  [325] 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       "  [361] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       "  [397] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       "  [433] 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [469] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       "  [505] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       "  [541] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       "  [577] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [613] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [649] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
       "  [685] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [721] 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       "  [757] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [793] 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
       "  [829] 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [865] 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       "  [901] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [937] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       "  [973] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
       " [1009] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [1045] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
       " [1081] 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0\n",
       " [1117] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [1153] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [1189] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
       " [1225] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       " [1261] 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [1297] 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [1333] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
       " [1369] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [1405] 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
       " [1441] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
       " [1477] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       " [1513] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [1549] 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [1585] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
       " [1621] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [1657] 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [1693] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
       " [1729] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [1765] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [1801] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [1837] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [1873] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
       " [1909] 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
       " [1945] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       " [1981] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2017] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       " [2053] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       " [2089] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [2125] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2161] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2197] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       " [2233] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2269] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2305] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
       " [2341] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2377] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2413] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
       " [2449] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       " [2485] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2521] 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       " [2557] 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       " [2593] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2629] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       " [2665] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
       " [2701] 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2737] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2773] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2809] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2845] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [2881] 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       " [2917] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2953] 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2989] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       " [3025] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
       " [3061] 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0\n",
       " [3097] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3133] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [3169] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3205] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0\n",
       " [3241] 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3277] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
       " [3313] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3349] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3385] 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
       " [3421] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3457] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3493] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [3529] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
       " [3565] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       " [3601] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3637] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1\n",
       " [3673] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1\n",
       " [3709] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [3745] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3781] 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       " [3817] 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [3853] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3889] 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [3925] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3961] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3997] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [4033] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       " [4069] 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [4105] 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4141] 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       " [4177] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [4213] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4249] 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4285] 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
       " [4321] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [4357] 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
       " [4393] 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0\n",
       " [4429] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [4465] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       " [4501] 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4537] 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4573] 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4609] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       " [4645] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [4681] 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
       " [4717] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4753] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
       " [4789] 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4825] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [4861] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4897] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4933] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       " [4969] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5005] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
       " [5041] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [5077] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       " [5113] 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
       " [5149] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [5185] 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5221] 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5257] 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5293] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [5329] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5365] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5401] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [5437] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
       " [5473] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [5509] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5545] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5581] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       " [5617] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
       " [5653] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5689] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [5725] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       " [5761] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5797] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
       " [5833] 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [5869] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5905] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       " [5941] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [5977] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [6013] 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
       " [6049] 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6085] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6121] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
       " [6157] 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
       " [6193] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6229] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6265] 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6301] 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
       " [6337] 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
       " [6373] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6409] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6445] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6481] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6517] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
       " [6553] 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6589] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
       " [6625] 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
       " [6661] 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
       " [6697] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6733] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6769] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6805] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6841] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
       " [6877] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6913] 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6949] 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [6985] 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7021] 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7057] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7093] 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [7129] 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
       " [7165] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [7201] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7237] 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
       " [7273] 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7309] 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7345] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       " [7381] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7417] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       " [7453] 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7489] 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7525] 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7561] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7597] 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1\n",
       " [7633] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
       " [7669] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [7705] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       " [7741] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [7777] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7813] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7849] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
       " [7885] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7921] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
       " [7957] 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       " [7993] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
       " [8029] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8065] 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
       " [8101] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8137] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
       " [8173] 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8209] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [8245] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       " [8281] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [8317] 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8353] 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [8389] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8425] 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8461] 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8497] 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8533] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       " [8569] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8605] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
       " [8641] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8677] 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8713] 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       " [8749] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8785] 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
       " [8821] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
       " [8857] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [8893] 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8929] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       " [8965] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9001] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9037] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9073] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [9109] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
       " [9145] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [9181] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [9217] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9253] 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9289] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
       " [9325] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9361] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
       " [9397] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9433] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9469] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9505] 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9541] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [9577] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9613] 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9649] 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
       " [9685] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [9721] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [9757] 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9793] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9829] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9865] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9901] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9937] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [9973] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10009] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
       "[10045] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       "[10081] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10117] 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
       "[10153] 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10189] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10225] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10261] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10297] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
       "[10333] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
       "[10369] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10405] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
       "[10441] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10477] 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       "[10513] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10549] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       "[10585] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       "[10621] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       "[10657] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
       "[10693] 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1\n",
       "[10729] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10765] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
       "[10801] 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10837] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       "[10873] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10909] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10945] 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       "[10981] 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       "[11017] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
       "[11053] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11089] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       "[11125] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11161] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       "[11197] 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11233] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11269] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
       "[11305] 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       "[11341] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11377] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11413] 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11449] 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11485] 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       "[11521] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       "[11557] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11593] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
       "[11629] 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11665] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11701] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11737] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       "[11773] 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
       "[11809] 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11845] 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11881] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11917] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
       "[11953] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
       "[11989] 0 0 0 0 0 1 0 0 0 0 0 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#definimos una función clasificadora de ols\n",
    "clasif <- function(pred, p){\n",
    "    r = pred > p\n",
    "    return(as.numeric(r))\n",
    "    }\n",
    "clasif(ols_pred, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a8d6f32-0584-401b-9f31-e9d981bd92d6",
   "metadata": {
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1653562468394,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "9a8d6f32-0584-401b-9f31-e9d981bd92d6"
   },
   "outputs": [],
   "source": [
    "confusion <- function(pred, y){\n",
    "    vp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    vn = 0\n",
    "    for (i in 1:length(pred)){\n",
    "        if(pred[i] == 1 ){\n",
    "            if(pred[i] == y[i]){\n",
    "                vp <- vp+1}\n",
    "            else{\n",
    "                fp <- fp+1}\n",
    "               }\n",
    "        else{\n",
    "             if(pred[i] != y[i]){\n",
    "                fn <- fn+1}\n",
    "            else{\n",
    "                vn <- vn+1\n",
    "                }\n",
    "            }}\n",
    "        return(cbind(c(vp,fp),c(fn,vn)))\n",
    "        }\n",
    "\n",
    "f1_score <- function(pred,y) {\n",
    "    val <- confusion(pred,y)\n",
    "    prec <- val[1]/(val[1]+val[2])\n",
    "    rec <- val[1]/(val[1]+val[3])\n",
    "    f1 <- 2/(prec^-1+rec^-1)\n",
    "    return(f1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd80f1ea-b267-4a02-bff2-59adf0573475",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1653562468395,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "bd80f1ea-b267-4a02-bff2-59adf0573475",
    "outputId": "0f235f31-83fc-4b1d-f9a5-36865a459c47"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 2 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>2726</td><td>1072</td></tr>\n",
       "\t<tr><td>4176</td><td>4026</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 2 of type dbl\n",
       "\\begin{tabular}{ll}\n",
       "\t 2726 & 1072\\\\\n",
       "\t 4176 & 4026\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 2 of type dbl\n",
       "\n",
       "| 2726 | 1072 |\n",
       "| 4176 | 4026 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2]\n",
       "[1,] 2726 1072\n",
       "[2,] 4176 4026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion(clasif(ols_pred, 0.3),y.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7894d770-aaee-4711-89b4-4968567d712e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 62,
     "status": "ok",
     "timestamp": 1653562468395,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "7894d770-aaee-4711-89b4-4968567d712e",
    "outputId": "b1c05c73-d423-494f-d282-c36702cd15fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>f1:</strong> 0.509532710280374"
      ],
      "text/latex": [
       "\\textbf{f1:} 0.509532710280374"
      ],
      "text/markdown": [
       "**f1:** 0.509532710280374"
      ],
      "text/plain": [
       "       f1 \n",
       "0.5095327 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ols_rdos['f1'] <- f1_score(clasif(ols_pred, 0.3),y.test)\n",
    "ols_rdos['f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2f2d27-ee1b-4cb4-ba24-64f76bbcc44b",
   "metadata": {
    "id": "fc2f2d27-ee1b-4cb4-ba24-64f76bbcc44b"
   },
   "source": [
    "Como se puede observar el modelo mínimos cuadrados ya no parece ser tan buen modelo para clasificaciones. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2ab693-79ff-4a79-8866-a8966aba212a",
   "metadata": {
    "id": "9e2ab693-79ff-4a79-8866-a8966aba212a"
   },
   "source": [
    "### Modelo logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7370cea2-1362-4217-adb1-7b1892e35c7d",
   "metadata": {
    "id": "7370cea2-1362-4217-adb1-7b1892e35c7d"
   },
   "source": [
    "El problema que tiene el modelo lineal para determinar una probabilidad, es que a menudo arroja valores negativos o valores mayores a 1, lo que no son valores que puedan identificarse como probabilidades. Para solucionar esto, se considera la función logística que devuelve todos valores entre 0 y 1.\n",
    "\n",
    "\\begin{equation}\n",
    "p\\left(y = 1|\\boldsymbol{X}=x\\right)=p\\left(\\boldsymbol{X}\\right) = \\frac{e^{\\boldsymbol{X}\\boldsymbol{\\beta}}}{1+e^{\\boldsymbol{X}\\boldsymbol{\\beta}}}\n",
    "\\end{equation}\n",
    "\n",
    "Si aplicamos transformaciones podemos ver que la ecuación nos queda de la siguiente forma:\n",
    "\n",
    "\\begin{equation}\n",
    "log\\left(\\frac{p\\left(\\boldsymbol{X}\\right)}{1-p\\left(\\boldsymbol{X}\\right)}\\right) = \\boldsymbol{X}\\boldsymbol{\\beta}\n",
    "\\end{equation}\n",
    "\n",
    "la proporción $\\frac{p\\left(\\boldsymbol{X}\\right)}{1-p\\left(\\boldsymbol{X}\\right)}$ se denomina *odds*, y puede tomar valores que van del 0 al $\\infty$. Como podemos ver el modelo de regresión sigue siendo lineal en $\\boldsymbol{X}$ pero con respecto al *log-odds* que es como se denomina a la parte de la izquierda de la ecuación anterior.\n",
    "\n",
    "La forma de estimar este modelo es a través de máxima verosimilitud, en el cual no vamos a entrar en detalles acá.\n",
    "\n",
    "Para realizar la estimación en R, se utiliza la función *glm*. La forma de uso es muy similar a *lm* necesita que le pasemos la fórmula a estimar y los datos necesarios como variables principales. Además se le agrega la variable *family* en la cual hay que colocarle que queremos estimar una *binomial*. Esta función en R es mucho más amplia que solo para estimar modelos logit, en realidad funcióna para estimar cualquier modelo lineal generalizado, lo que hay que variar es el parámetro *family*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c4ba188-21fd-482c-9875-e03d5ccfd5ef",
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1653562468396,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "2c4ba188-21fd-482c-9875-e03d5ccfd5ef"
   },
   "outputs": [],
   "source": [
    "logit <- glm(linear, data = X.train, family = \"binomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e359c955-6a0e-4e87-8ec8-32bdecdefabd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1653562468396,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "e359c955-6a0e-4e87-8ec8-32bdecdefabd",
    "outputId": "3d214a3d-485d-4397-9260-4bdcd1778442"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = linear, family = \"binomial\", data = X.train)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.7921  -0.8927  -0.6873   1.2404   2.3396  \n",
       "\n",
       "Coefficients:\n",
       "                          Estimate Std. Error  z value Pr(>|z|)    \n",
       "(Intercept)              -0.827108   0.006952 -118.976  < 2e-16 ***\n",
       "yob                      -0.146646   0.007391  -19.841  < 2e-16 ***\n",
       "hh_size                   0.021169   0.007162    2.956  0.00312 ** \n",
       "sex                      -0.021452   0.006784   -3.162  0.00157 ** \n",
       "city                      0.205738   0.006960   29.560  < 2e-16 ***\n",
       "g2000                    -0.033104   0.007648   -4.328 1.50e-05 ***\n",
       "g2002                     0.175047   0.008076   21.676  < 2e-16 ***\n",
       "p2000                     0.179223   0.006727   26.642  < 2e-16 ***\n",
       "p2002                     0.274766   0.006917   39.722  < 2e-16 ***\n",
       "p2004                     0.370565   0.006940   53.393  < 2e-16 ***\n",
       "totalpopulation_estimate  0.055280   0.008801    6.281 3.36e-10 ***\n",
       "percent_male             -0.020053   0.008079   -2.482  0.01306 *  \n",
       "median_age                0.014068   0.016611    0.847  0.39704    \n",
       "percent_62yearsandover    0.030613   0.016222    1.887  0.05914 .  \n",
       "percent_white             0.103865   0.018110    5.735 9.73e-09 ***\n",
       "percent_black             0.094443   0.016144    5.850 4.91e-09 ***\n",
       "median_income             0.128761   0.015803    8.148 3.71e-16 ***\n",
       "employ_20to64            -0.065458   0.009579   -6.834 8.27e-12 ***\n",
       "highschool                0.148603   0.024568    6.049 1.46e-09 ***\n",
       "bach_orhigher             0.037475   0.026861    1.395  0.16298    \n",
       "percent_hispanicorlatino  0.007410   0.009286    0.798  0.42490    \n",
       "noise1                   -0.001339   0.006776   -0.198  0.84335    \n",
       "noise2                    0.003072   0.006775    0.453  0.65023    \n",
       "noise3                   -0.012532   0.006780   -1.848  0.06453 .  \n",
       "noise4                   -0.011643   0.006776   -1.718  0.08576 .  \n",
       "noise5                   -0.004496   0.006771   -0.664  0.50668    \n",
       "noise6                    0.012333   0.006772    1.821  0.06857 .  \n",
       "noise7                    0.002257   0.006773    0.333  0.73889    \n",
       "noise8                    0.006287   0.006777    0.928  0.35356    \n",
       "noise9                   -0.002648   0.006774   -0.391  0.69586    \n",
       "noise10                   0.005069   0.006774    0.748  0.45432    \n",
       "noise11                   0.002125   0.006776    0.314  0.75381    \n",
       "noise12                  -0.000618   0.006774   -0.091  0.92731    \n",
       "noise13                   0.005960   0.006773    0.880  0.37884    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 135158  on 107998  degrees of freedom\n",
       "Residual deviance: 127323  on 107965  degrees of freedom\n",
       "AIC: 127391\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fc6bc0-4b94-4373-955c-b74c466a3654",
   "metadata": {
    "id": "24fc6bc0-4b94-4373-955c-b74c466a3654"
   },
   "source": [
    "La función predict también es aplicable a los modelos logit, pero a estos hay que agregarles el parámetro *type* en el cual hay que poner response. En otro caso, nos devolvera la probabilidad en escala logarítmica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7102dbf0-636e-4a88-8d2f-1d6a9e8ce551",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1653562468396,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "7102dbf0-636e-4a88-8d2f-1d6a9e8ce551",
    "outputId": "efc8cbfa-82a3-499b-91e3-2b997cf68bbc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>mse_logit</dt><dd>0.2019256731299</dd><dt>,mse_test</dt><dd>0.201433282285898</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[mse\\textbackslash{}\\_logit] 0.2019256731299\n",
       "\\item[,mse\\textbackslash{}\\_test] 0.201433282285898\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "mse_logit\n",
       ":   0.2019256731299,mse_test\n",
       ":   0.201433282285898\n",
       "\n"
      ],
      "text/plain": [
       "mse_logit ,mse_test \n",
       "0.2019257 0.2014333 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit_pred <- predict(logit,X.test, type = \"response\")\n",
    "logit_rdos <- c('mse_logit' = mse(predict(logit, type = \"response\"), y.train),',mse_test' = mse(logit_pred, y.test)) \n",
    "logit_rdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4478557c-fa9a-4aaa-8f94-0e42ee79f88f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1653562468397,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "4478557c-fa9a-4aaa-8f94-0e42ee79f88f",
    "outputId": "f4e0109e-7858-4dba-db1f-b21689f8ef1c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>...</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>1</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li><li>0</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item ...\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 0\n",
       "3. 0\n",
       "4. 0\n",
       "5. 0\n",
       "6. 0\n",
       "7. 0\n",
       "8. 1\n",
       "9. 0\n",
       "10. 0\n",
       "11. 0\n",
       "12. 0\n",
       "13. 0\n",
       "14. 1\n",
       "15. 0\n",
       "16. 0\n",
       "17. 0\n",
       "18. 0\n",
       "19. 0\n",
       "20. 0\n",
       "21. 0\n",
       "22. 0\n",
       "23. 0\n",
       "24. 0\n",
       "25. 0\n",
       "26. 1\n",
       "27. 0\n",
       "28. 0\n",
       "29. 1\n",
       "30. 0\n",
       "31. 1\n",
       "32. 0\n",
       "33. 0\n",
       "34. 0\n",
       "35. 0\n",
       "36. 0\n",
       "37. 0\n",
       "38. 0\n",
       "39. 1\n",
       "40. 0\n",
       "41. 0\n",
       "42. 0\n",
       "43. 0\n",
       "44. 0\n",
       "45. 0\n",
       "46. 0\n",
       "47. 0\n",
       "48. 0\n",
       "49. 1\n",
       "50. 0\n",
       "51. 0\n",
       "52. 0\n",
       "53. 0\n",
       "54. 0\n",
       "55. 0\n",
       "56. 0\n",
       "57. 0\n",
       "58. 0\n",
       "59. 0\n",
       "60. 0\n",
       "61. 0\n",
       "62. 0\n",
       "63. 1\n",
       "64. 0\n",
       "65. 0\n",
       "66. 1\n",
       "67. 1\n",
       "68. 0\n",
       "69. 0\n",
       "70. 0\n",
       "71. 0\n",
       "72. 0\n",
       "73. 0\n",
       "74. 0\n",
       "75. 0\n",
       "76. 1\n",
       "77. 0\n",
       "78. 0\n",
       "79. 0\n",
       "80. 0\n",
       "81. 0\n",
       "82. 0\n",
       "83. 0\n",
       "84. 0\n",
       "85. 0\n",
       "86. 1\n",
       "87. 0\n",
       "88. 0\n",
       "89. 0\n",
       "90. 0\n",
       "91. 0\n",
       "92. 0\n",
       "93. 0\n",
       "94. 0\n",
       "95. 0\n",
       "96. 0\n",
       "97. 0\n",
       "98. 0\n",
       "99. 0\n",
       "100. 0\n",
       "101. 0\n",
       "102. 0\n",
       "103. 0\n",
       "104. 0\n",
       "105. 0\n",
       "106. 0\n",
       "107. 1\n",
       "108. 1\n",
       "109. 1\n",
       "110. 0\n",
       "111. 0\n",
       "112. 0\n",
       "113. 0\n",
       "114. 0\n",
       "115. 0\n",
       "116. 0\n",
       "117. 0\n",
       "118. 0\n",
       "119. 0\n",
       "120. 0\n",
       "121. 0\n",
       "122. 0\n",
       "123. 0\n",
       "124. 0\n",
       "125. 0\n",
       "126. 1\n",
       "127. 1\n",
       "128. 0\n",
       "129. 0\n",
       "130. 0\n",
       "131. 0\n",
       "132. 0\n",
       "133. 0\n",
       "134. 0\n",
       "135. 0\n",
       "136. 0\n",
       "137. 0\n",
       "138. 0\n",
       "139. 0\n",
       "140. 0\n",
       "141. 0\n",
       "142. 0\n",
       "143. 0\n",
       "144. 0\n",
       "145. 1\n",
       "146. 0\n",
       "147. 0\n",
       "148. 0\n",
       "149. 0\n",
       "150. 0\n",
       "151. 0\n",
       "152. 1\n",
       "153. 0\n",
       "154. 0\n",
       "155. 0\n",
       "156. 0\n",
       "157. 1\n",
       "158. 0\n",
       "159. 0\n",
       "160. 0\n",
       "161. 0\n",
       "162. 0\n",
       "163. 0\n",
       "164. 0\n",
       "165. 0\n",
       "166. 0\n",
       "167. 0\n",
       "168. 0\n",
       "169. 0\n",
       "170. 0\n",
       "171. 0\n",
       "172. 0\n",
       "173. 0\n",
       "174. 1\n",
       "175. 0\n",
       "176. 0\n",
       "177. 0\n",
       "178. 0\n",
       "179. 0\n",
       "180. 0\n",
       "181. 0\n",
       "182. 0\n",
       "183. 0\n",
       "184. 0\n",
       "185. 0\n",
       "186. 0\n",
       "187. 1\n",
       "188. 0\n",
       "189. 0\n",
       "190. 0\n",
       "191. 0\n",
       "192. 0\n",
       "193. 0\n",
       "194. 0\n",
       "195. 0\n",
       "196. 0\n",
       "197. 0\n",
       "198. 0\n",
       "199. 0\n",
       "200. 1\n",
       "201. ...\n",
       "202. 1\n",
       "203. 0\n",
       "204. 0\n",
       "205. 0\n",
       "206. 0\n",
       "207. 0\n",
       "208. 0\n",
       "209. 0\n",
       "210. 0\n",
       "211. 0\n",
       "212. 1\n",
       "213. 0\n",
       "214. 0\n",
       "215. 0\n",
       "216. 0\n",
       "217. 0\n",
       "218. 0\n",
       "219. 0\n",
       "220. 0\n",
       "221. 0\n",
       "222. 1\n",
       "223. 0\n",
       "224. 0\n",
       "225. 0\n",
       "226. 0\n",
       "227. 0\n",
       "228. 1\n",
       "229. 0\n",
       "230. 0\n",
       "231. 0\n",
       "232. 0\n",
       "233. 0\n",
       "234. 0\n",
       "235. 0\n",
       "236. 0\n",
       "237. 0\n",
       "238. 0\n",
       "239. 0\n",
       "240. 0\n",
       "241. 0\n",
       "242. 0\n",
       "243. 0\n",
       "244. 0\n",
       "245. 0\n",
       "246. 1\n",
       "247. 0\n",
       "248. 1\n",
       "249. 0\n",
       "250. 0\n",
       "251. 0\n",
       "252. 0\n",
       "253. 1\n",
       "254. 0\n",
       "255. 0\n",
       "256. 0\n",
       "257. 0\n",
       "258. 0\n",
       "259. 0\n",
       "260. 0\n",
       "261. 1\n",
       "262. 0\n",
       "263. 0\n",
       "264. 0\n",
       "265. 0\n",
       "266. 0\n",
       "267. 0\n",
       "268. 0\n",
       "269. 0\n",
       "270. 0\n",
       "271. 0\n",
       "272. 0\n",
       "273. 0\n",
       "274. 0\n",
       "275. 0\n",
       "276. 0\n",
       "277. 0\n",
       "278. 0\n",
       "279. 0\n",
       "280. 0\n",
       "281. 0\n",
       "282. 0\n",
       "283. 0\n",
       "284. 0\n",
       "285. 0\n",
       "286. 0\n",
       "287. 0\n",
       "288. 1\n",
       "289. 0\n",
       "290. 0\n",
       "291. 0\n",
       "292. 0\n",
       "293. 0\n",
       "294. 0\n",
       "295. 0\n",
       "296. 0\n",
       "297. 0\n",
       "298. 0\n",
       "299. 0\n",
       "300. 0\n",
       "301. 0\n",
       "302. 0\n",
       "303. 0\n",
       "304. 1\n",
       "305. 0\n",
       "306. 0\n",
       "307. 0\n",
       "308. 0\n",
       "309. 0\n",
       "310. 0\n",
       "311. 0\n",
       "312. 0\n",
       "313. 0\n",
       "314. 0\n",
       "315. 0\n",
       "316. 0\n",
       "317. 0\n",
       "318. 0\n",
       "319. 0\n",
       "320. 0\n",
       "321. 0\n",
       "322. 0\n",
       "323. 0\n",
       "324. 0\n",
       "325. 0\n",
       "326. 0\n",
       "327. 0\n",
       "328. 0\n",
       "329. 0\n",
       "330. 0\n",
       "331. 0\n",
       "332. 0\n",
       "333. 0\n",
       "334. 0\n",
       "335. 0\n",
       "336. 0\n",
       "337. 0\n",
       "338. 0\n",
       "339. 0\n",
       "340. 0\n",
       "341. 1\n",
       "342. 0\n",
       "343. 0\n",
       "344. 0\n",
       "345. 0\n",
       "346. 1\n",
       "347. 0\n",
       "348. 0\n",
       "349. 0\n",
       "350. 0\n",
       "351. 0\n",
       "352. 0\n",
       "353. 0\n",
       "354. 0\n",
       "355. 0\n",
       "356. 0\n",
       "357. 0\n",
       "358. 0\n",
       "359. 0\n",
       "360. 0\n",
       "361. 1\n",
       "362. 0\n",
       "363. 0\n",
       "364. 0\n",
       "365. 0\n",
       "366. 0\n",
       "367. 0\n",
       "368. 0\n",
       "369. 0\n",
       "370. 0\n",
       "371. 0\n",
       "372. 0\n",
       "373. 0\n",
       "374. 0\n",
       "375. 0\n",
       "376. 0\n",
       "377. 0\n",
       "378. 0\n",
       "379. 0\n",
       "380. 0\n",
       "381. 0\n",
       "382. 1\n",
       "383. 0\n",
       "384. 0\n",
       "385. 0\n",
       "386. 0\n",
       "387. 0\n",
       "388. 1\n",
       "389. 0\n",
       "390. 0\n",
       "391. 0\n",
       "392. 0\n",
       "393. 0\n",
       "394. 0\n",
       "395. 1\n",
       "396. 0\n",
       "397. 0\n",
       "398. 0\n",
       "399. 0\n",
       "400. 0\n",
       "401. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    [1] 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0\n",
       "   [37] 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0\n",
       "   [73] 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
       "  [109] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [145] 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       "  [181] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [217] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [253] 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       "  [289] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       "  [325] 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       "  [361] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       "  [397] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       "  [433] 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [469] 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       "  [505] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       "  [541] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       "  [577] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [613] 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [649] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0\n",
       "  [685] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [721] 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       "  [757] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [793] 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
       "  [829] 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [865] 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
       "  [901] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "  [937] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
       "  [973] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
       " [1009] 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
       " [1045] 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
       " [1081] 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0\n",
       " [1117] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       " [1153] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [1189] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
       " [1225] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       " [1261] 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [1297] 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [1333] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
       " [1369] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [1405] 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
       " [1441] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
       " [1477] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
       " [1513] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [1549] 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [1585] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
       " [1621] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
       " [1657] 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [1693] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
       " [1729] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [1765] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [1801] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [1837] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
       " [1873] 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0\n",
       " [1909] 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
       " [1945] 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       " [1981] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2017] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       " [2053] 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       " [2089] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [2125] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2161] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2197] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       " [2233] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2269] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2305] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
       " [2341] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       " [2377] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2413] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
       " [2449] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       " [2485] 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2521] 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       " [2557] 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       " [2593] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2629] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       " [2665] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
       " [2701] 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2737] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2773] 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2809] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       " [2845] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [2881] 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       " [2917] 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2953] 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [2989] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       " [3025] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
       " [3061] 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0\n",
       " [3097] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3133] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
       " [3169] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3205] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0\n",
       " [3241] 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3277] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1\n",
       " [3313] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3349] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3385] 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
       " [3421] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3457] 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3493] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [3529] 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
       " [3565] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       " [3601] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3637] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1\n",
       " [3673] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1\n",
       " [3709] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [3745] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3781] 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       " [3817] 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [3853] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3889] 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [3925] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3961] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [3997] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [4033] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
       " [4069] 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [4105] 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4141] 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       " [4177] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [4213] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       " [4249] 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4285] 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
       " [4321] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [4357] 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1\n",
       " [4393] 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
       " [4429] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [4465] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       " [4501] 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4537] 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4573] 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4609] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
       " [4645] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [4681] 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
       " [4717] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       " [4753] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0\n",
       " [4789] 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
       " [4825] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [4861] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4897] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [4933] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       " [4969] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5005] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
       " [5041] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [5077] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       " [5113] 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
       " [5149] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [5185] 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5221] 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5257] 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5293] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [5329] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5365] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5401] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [5437] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
       " [5473] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [5509] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5545] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [5581] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       " [5617] 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
       " [5653] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5689] 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [5725] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       " [5761] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
       " [5797] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
       " [5833] 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0\n",
       " [5869] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [5905] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       " [5941] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [5977] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [6013] 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
       " [6049] 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6085] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6121] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
       " [6157] 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
       " [6193] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6229] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6265] 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6301] 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
       " [6337] 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
       " [6373] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6409] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6445] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6481] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6517] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
       " [6553] 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6589] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
       " [6625] 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
       " [6661] 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
       " [6697] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
       " [6733] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6769] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6805] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6841] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
       " [6877] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6913] 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [6949] 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [6985] 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7021] 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7057] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7093] 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [7129] 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
       " [7165] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [7201] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7237] 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0\n",
       " [7273] 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7309] 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7345] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0\n",
       " [7381] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
       " [7417] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       " [7453] 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7489] 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7525] 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7561] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7597] 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1\n",
       " [7633] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
       " [7669] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [7705] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
       " [7741] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [7777] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7813] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7849] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1\n",
       " [7885] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [7921] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
       " [7957] 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       " [7993] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
       " [8029] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8065] 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
       " [8101] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8137] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
       " [8173] 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8209] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       " [8245] 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
       " [8281] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
       " [8317] 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8353] 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
       " [8389] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8425] 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8461] 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8497] 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8533] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       " [8569] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
       " [8605] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1\n",
       " [8641] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8677] 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8713] 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       " [8749] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [8785] 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
       " [8821] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
       " [8857] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [8893] 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [8929] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       " [8965] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9001] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9037] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9073] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [9109] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
       " [9145] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [9181] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [9217] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9253] 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9289] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
       " [9325] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9361] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
       " [9397] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9433] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9469] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9505] 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
       " [9541] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [9577] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9613] 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       " [9649] 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
       " [9685] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
       " [9721] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       " [9757] 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9793] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9829] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9865] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9901] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       " [9937] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       " [9973] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       "[10009] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
       "[10045] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       "[10081] 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       "[10117] 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1\n",
       "[10153] 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10189] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
       "[10225] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
       "[10261] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10297] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
       "[10333] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
       "[10369] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10405] 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
       "[10441] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10477] 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
       "[10513] 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10549] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       "[10585] 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       "[10621] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
       "[10657] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1\n",
       "[10693] 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1\n",
       "[10729] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10765] 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
       "[10801] 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10837] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
       "[10873] 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[10909] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
       "[10945] 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
       "[10981] 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       "[11017] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
       "[11053] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       "[11089] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
       "[11125] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
       "[11161] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
       "[11197] 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11233] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11269] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
       "[11305] 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
       "[11341] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       "[11377] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
       "[11413] 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11449] 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11485] 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0\n",
       "[11521] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       "[11557] 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11593] 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
       "[11629] 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
       "[11665] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11701] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11737] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
       "[11773] 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
       "[11809] 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11845] 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11881] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "[11917] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
       "[11953] 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
       "[11989] 0 0 0 0 0 1 0 0 0 0 0 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# La fórmula predict en el logit devuelve una probabilidad entonces tampoco arroja valores 0 o 1 como la clasificación que queremos, por lo tanto lo tenemos que separar en base a un criterio\n",
    "# usamos la función creada antes\n",
    "clasif(logit_pred, 0.5) \n",
    "logit_rdos['f1'] <- f1_score(clasif(logit_pred, 0.3) , y.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06df185f-7caf-4baf-a89c-3ca593fdf5a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1653562468398,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "06df185f-7caf-4baf-a89c-3ca593fdf5a9",
    "outputId": "8ccf3eae-596a-41f9-88e9-f6ed57f0ca79"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>f1:</strong> 0.502742946708464"
      ],
      "text/latex": [
       "\\textbf{f1:} 0.502742946708464"
      ],
      "text/markdown": [
       "**f1:** 0.502742946708464"
      ],
      "text/plain": [
       "       f1 \n",
       "0.5027429 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit_rdos['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5de6e5be-9eed-4753-b354-2cb29104b6ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1653562468399,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "5de6e5be-9eed-4753-b354-2cb29104b6ca",
    "outputId": "2d819140-d4af-4a2d-e207-cf8f8f1d511b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 3 × 2 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>ols_rdos</th><th scope=col>logit_rdos</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>mse_train</th><td>0.2019455</td><td>0.2019257</td></tr>\n",
       "\t<tr><th scope=row>mse_test</th><td>0.2012196</td><td>0.2014333</td></tr>\n",
       "\t<tr><th scope=row>f1</th><td>0.5095327</td><td>0.5027429</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 2 of type dbl\n",
       "\\begin{tabular}{r|ll}\n",
       "  & ols\\_rdos & logit\\_rdos\\\\\n",
       "\\hline\n",
       "\tmse\\_train & 0.2019455 & 0.2019257\\\\\n",
       "\tmse\\_test & 0.2012196 & 0.2014333\\\\\n",
       "\tf1 & 0.5095327 & 0.5027429\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 2 of type dbl\n",
       "\n",
       "| <!--/--> | ols_rdos | logit_rdos |\n",
       "|---|---|---|\n",
       "| mse_train | 0.2019455 | 0.2019257 |\n",
       "| mse_test | 0.2012196 | 0.2014333 |\n",
       "| f1 | 0.5095327 | 0.5027429 |\n",
       "\n"
      ],
      "text/plain": [
       "          ols_rdos  logit_rdos\n",
       "mse_train 0.2019455 0.2019257 \n",
       "mse_test  0.2012196 0.2014333 \n",
       "f1        0.5095327 0.5027429 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ponemos ambos modelos en un df que va agrupando los resultados\n",
    "rdos <- cbind(ols_rdos,logit_rdos)\n",
    "rdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e52e957-69d5-476b-a8c6-21dc7ee75780",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 96
    },
    "executionInfo": {
     "elapsed": 3570,
     "status": "error",
     "timestamp": 1653562471910,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "0e52e957-69d5-476b-a8c6-21dc7ee75780",
    "outputId": "4221818a-6292-43c0-b175-da3548af4494"
   },
   "outputs": [],
   "source": [
    "ols2 <- lm(linear.inter, data = X.train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48e23507-4103-4883-844f-eaee8cae850e",
   "metadata": {
    "executionInfo": {
     "elapsed": 340626,
     "status": "aborted",
     "timestamp": 1653562471912,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "48e23507-4103-4883-844f-eaee8cae850e"
   },
   "outputs": [],
   "source": [
    "logit2 <- glm(linear.inter, data = X.train, family = \"binomial\")\n",
    "#mse(logit2, X.train, X.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747bafa4-bf0b-4271-983b-e37496d74a95",
   "metadata": {
    "id": "747bafa4-bf0b-4271-983b-e37496d74a95"
   },
   "source": [
    "### Regresion con descomposcición de valores singulares\n",
    "\n",
    "Un método utilizado por los sowtwares de predicción en machine learning es la regresión utilizando la pseudo inversa de la matriz de datos. Para encontrar dicha pseudo-inversa se utiliza la descomposición de valores singulares. Sea $A$ una matriz $n\\ x\\  p$ \n",
    "\n",
    "\\begin{equation}\n",
    "A = U\\Sigma V^T\n",
    "\\end{equation}\n",
    "\n",
    "siendo $U$ una matriz $n\\ x\\ n$ , $\\Sigma$ es una matriz $m\\ x\\ p$ y $V^T$ es una matriz cuadrada $p\\ x\\ p$. Las matrices $U$ y $V^T$ son matrices unitarias lo que les da unas propiedades muy convenientes ya que $UU^T\\ =\\ I$ y $VV^T\\ =\\ I$. Por otro lado $\\Sigma$ es una matriz diagonal sólo en en sus primeros $r$ renglones siendo $r=\\ min(n,p)$ llenando todos los demás espacios con ceros, que suelen eliminarse. La primera ventaja que proporciona este método es que no importa la forma de la matriz, siempre se puede descomponer en estas tres matrices mencionadas, incluso cuando $p > n$.\n",
    "\n",
    "Dado un sistema de ecuaciones, podemos resolverlo con la descomposición mencionada.\n",
    "\n",
    "\\begin{equation}\n",
    "Ax\\ =\\ b \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "(U\\Sigma V^T)^{-1}(U\\Sigma V^T)x\\ =\\ (U\\Sigma V^T)^{-1}b \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{x}\\ =\\ V\\Sigma^{-1}U^Tb\n",
    "\\end{equation}\n",
    "\n",
    "Cómo vemos las matriz descompuesta es muy fácil de invertir. La complejidad computacional en usar este método es al rededor de $O\\left(n^2\\right)$ mientras que con el método normal la complejidad es de alrededor de $O\\left(n^{2.4}\\right)$ hasta $O\\left(n^3\\right)$\n",
    "\n",
    "En R podemos encontrar la función *svd* que permite descomponer las matrices, luego con está podemos construir la regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fee2b146-0560-4133-8b30-d0f189380760",
   "metadata": {
    "executionInfo": {
     "elapsed": 340625,
     "status": "aborted",
     "timestamp": 1653562471913,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "fee2b146-0560-4133-8b30-d0f189380760"
   },
   "outputs": [],
   "source": [
    "# está función reg.svm devuelve los coeficientes calculados bajo este método\n",
    "reg.svm <- function(modelo, y,X) {\n",
    "    X <- model.matrix(modelo,X) #la función model.matrix devuleve la matriz de acuerdo a la fórmula\n",
    "    dX <- svd(X)\n",
    "    x_hat <- (dX$v) %*% solve(diag(dX$d)) %*% t(dX$u) %*% y\n",
    "    #y_pred <- X %*% x_hat\n",
    "    return(x_hat)\n",
    "    }\n",
    "#creamos una función predict\n",
    "\n",
    "predict.svm <- function(modelo, X, coef){\n",
    "    pred <- model.matrix(modelo,X) %*% coef\n",
    "    return(pred)\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1560464e-380e-4a66-aa6d-f56b6606685f",
   "metadata": {
    "executionInfo": {
     "elapsed": 340624,
     "status": "aborted",
     "timestamp": 1653562471916,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "1560464e-380e-4a66-aa6d-f56b6606685f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>mse_train</dt><dd>0.201945471512763</dd><dt>mse_test</dt><dd>0.201219570688055</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[mse\\textbackslash{}\\_train] 0.201945471512763\n",
       "\\item[mse\\textbackslash{}\\_test] 0.201219570688055\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "mse_train\n",
       ":   0.201945471512763mse_test\n",
       ":   0.201219570688055\n",
       "\n"
      ],
      "text/plain": [
       "mse_train  mse_test \n",
       "0.2019455 0.2012196 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef <- reg.svm(linear, y.train, X.train)\n",
    "pred_train <- predict.svm(linear, X.train, coef)\n",
    "pred_test <- predict.svm(linear, X.test, coef)\n",
    "\n",
    "svm_rdos <- c('mse_train' = mse(pred_train, y.train), 'mse_test' = mse(pred_test, y.test))\n",
    "svm_rdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d66f39a-b171-4ad0-8252-760c59b1c958",
   "metadata": {
    "executionInfo": {
     "elapsed": 340618,
     "status": "aborted",
     "timestamp": 1653562471917,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "1d66f39a-b171-4ad0-8252-760c59b1c958"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>f1:</strong> 0.509532710280374"
      ],
      "text/latex": [
       "\\textbf{f1:} 0.509532710280374"
      ],
      "text/markdown": [
       "**f1:** 0.509532710280374"
      ],
      "text/plain": [
       "       f1 \n",
       "0.5095327 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sigue con el mismo problema de clasificación usamos la función clasif creada y calculamos el f1\n",
    "svm_rdos['f1'] <- f1_score(clasif(pred_test,0.3), y.test)\n",
    "svm_rdos['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "397ddb71-6366-46b4-9eb2-a344324c0fee",
   "metadata": {
    "executionInfo": {
     "elapsed": 340615,
     "status": "aborted",
     "timestamp": 1653562471919,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "397ddb71-6366-46b4-9eb2-a344324c0fee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 3 × 3 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>ols_rdos</th><th scope=col>logit_rdos</th><th scope=col>svm_rdos</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>mse_train</th><td>0.2019455</td><td>0.2019257</td><td>0.2019455</td></tr>\n",
       "\t<tr><th scope=row>mse_test</th><td>0.2012196</td><td>0.2014333</td><td>0.2012196</td></tr>\n",
       "\t<tr><th scope=row>f1</th><td>0.5095327</td><td>0.5027429</td><td>0.5095327</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 3 of type dbl\n",
       "\\begin{tabular}{r|lll}\n",
       "  & ols\\_rdos & logit\\_rdos & svm\\_rdos\\\\\n",
       "\\hline\n",
       "\tmse\\_train & 0.2019455 & 0.2019257 & 0.2019455\\\\\n",
       "\tmse\\_test & 0.2012196 & 0.2014333 & 0.2012196\\\\\n",
       "\tf1 & 0.5095327 & 0.5027429 & 0.5095327\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 3 of type dbl\n",
       "\n",
       "| <!--/--> | ols_rdos | logit_rdos | svm_rdos |\n",
       "|---|---|---|---|\n",
       "| mse_train | 0.2019455 | 0.2019257 | 0.2019455 |\n",
       "| mse_test | 0.2012196 | 0.2014333 | 0.2012196 |\n",
       "| f1 | 0.5095327 | 0.5027429 | 0.5095327 |\n",
       "\n"
      ],
      "text/plain": [
       "          ols_rdos  logit_rdos svm_rdos \n",
       "mse_train 0.2019455 0.2019257  0.2019455\n",
       "mse_test  0.2012196 0.2014333  0.2012196\n",
       "f1        0.5095327 0.5027429  0.5095327"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rdos <- cbind(rdos,svm_rdos)\n",
    "rdos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d4a13d-d65c-42dc-9929-dd33a8a893c3",
   "metadata": {
    "id": "95d4a13d-d65c-42dc-9929-dd33a8a893c3"
   },
   "source": [
    "### Ridge regresión\n",
    "\n",
    "El teorema Gauss-Markov dice que el estimador de mínimos cuadrados es el mejor estimador lineal insesgado, pero puede ser que exista un estimador que sea sesgado y mejor. Esta discusión pasa por un trade-off entre el sesgo y la varianza muy usual en machine learning, como los objetivos acá no son la estimación si no la predicción se prefiere un estimador que sea sesgado mientras disminuya la varianza. Esto sucede con los estimadores restringidos. \n",
    "\n",
    "El estimador que proviene de la ridge regresión surje de solucionar el siguiente problema:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\beta}^{ridge} = argmin_β\\left(y_i-\\beta_0-\\sum_{j=1}^p\\beta_j^2\\right)^2\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "sujeto\\ a\\ \\sum_{j=1}^p\\beta_j^2\\ <= t\n",
    "\\end{equation}\n",
    "\n",
    "Resolviendo el problema el estimador nos queda de la siguiente forma:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\beta}^{ridge} = argmin_β\\left\\{\\left(y_i-\\beta_0-\\sum_{j=1}^p\\beta_j^2\\right)^2 + λ\\sum_{j=1}^p\\beta_j^2\\right\\}\n",
    "\\end{equation}\n",
    "\n",
    "El parámetro $\\lambda$ es el que regulariza los estimadores llevando a 0 los parámetros. La regresión ridge no es invariante a las escalas de los parámetros, es por eso que se deben estandarizar las variables previo a hacer los cálculos. \n",
    "\n",
    "Si escribimos el problema en forma matricial nos queda de la siguiente forma:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\beta}^{ridge} = \\left(\\boldsymbol{X}^T\\boldsymbol{X}+\\lambda\\boldsymbol{I} \\right)^{-1}\\boldsymbol{X}^T\\boldsymbol{y} \n",
    "\\end{equation}\n",
    "\n",
    "La matriz $\\boldsymbol{X}^T\\boldsymbol{X}$ puede no tener rango completo, incluso son los principales problemas perseguidos con este tipo de regresión y la forma de solucionarlo es con la descomposición de valores singulares.\n",
    "\n",
    "Para trabajar la regresión ridge y LASSO usamos el paquete glmnet y la función de ese mismo paquete. La forma de determinar cual vamos a utilizar es con el parámtero alpha, si este es 0 la regresión es ridge y si es 1 es LASSO.\n",
    "\n",
    "EL parámetro a identficar es el parámetro $\\lambda$, no hay una forma de saber que valor poner a este parámetro por eso lo ideal es hacer varias regresiones y tomar el que mejores resultados, para ello se hace un grid con un rango de posibles valores para lambda, en este caso desde $10^{10}$ hasta $10^{-2}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "927e35f4-a7b9-4e5b-99e6-0e616234ad23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1582,
     "status": "ok",
     "timestamp": 1653562522001,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "927e35f4-a7b9-4e5b-99e6-0e616234ad23",
    "outputId": "35193fc6-2a1d-48be-bd69-5289523ea2d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: glmnet\n",
      "\n",
      "Loading required package: Matrix\n",
      "\n",
      "Loaded glmnet 4.1-4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "require(glmnet)\n",
    "grid <- 10^seq(10,-2, length = 100)\n",
    "ridge.mod <- glmnet(model.matrix(linear, X.train), y.train, alpha = 0, lambda = grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ff2cb4-ac93-4b09-9534-f89945f0f20a",
   "metadata": {
    "id": "37ff2cb4-ac93-4b09-9534-f89945f0f20a"
   },
   "source": [
    "Lo que la función \"glmnet\" ha hecho ahora es calcular 100 regresiones para los distintos valores de $\\lambda$ que le pasamos, por lo tanto cuando queremos consultar los coeficientes que arroja el modelo, se hace con el método \"coef\" y este va arrojar una matriz de k * 100 siendo k la cantidad de coeficientes que estamos estimando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "679df4a0-0b24-4c8d-acc8-58e3c41c7899",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1653566779258,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "679df4a0-0b24-4c8d-acc8-58e3c41c7899",
    "outputId": "9b242b8b-b490-4f4f-a3af-fa0888430da6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>35</li><li>100</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 35\n",
       "\\item 100\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 35\n",
       "2. 100\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  35 100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(coef(ridge.mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20085cb-afe1-44da-ac37-fb682462b09b",
   "metadata": {},
   "source": [
    "El hiper parámetro $\\lambda$ se selecciona con cross-validation. Recordemos que la elección de los bloques en las carpetas de cross-validation se hace de manera aleatoria, entonces para poder repetir el experimento es necesario pasarle una semilla al software, así siempre nos arroja los mismos datos\n",
    "\n",
    "Para ejecutar la cross-validation en R se utiliza la función cv.glmnet y los parámetros que recibe son los mismos que los que recibe glmnet y se le agregan los de cross-validations. El argumento lambda es opcional, se puede pasar una lista propia o si se deja vació el programa tomara distintos lambda por defecto. La cantidad de carpetas está por defecto en 10 que también puede ser modificada. Entre los argumentos de salida podemos encontrar a lambda.min que representa el valor de lambda que minimiza el error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a2ea785-6c3c-46f7-9e6d-73014c8faf6e",
   "metadata": {
    "executionInfo": {
     "elapsed": 340605,
     "status": "aborted",
     "timestamp": 1653562471921,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "8a2ea785-6c3c-46f7-9e6d-73014c8faf6e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0465895718498589"
      ],
      "text/latex": [
       "0.0465895718498589"
      ],
      "text/markdown": [
       "0.0465895718498589"
      ],
      "text/plain": [
       "[1] 0.04658957"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(154)\n",
    "cv_ <- cv.glmnet(as.matrix(X.train), y.train, alpha = 0)\n",
    "plot(cv_)\n",
    "bestlam <- cv_$lambda.min\n",
    "bestlam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4f6540-c098-4d2d-9790-48b80d77ed62",
   "metadata": {},
   "source": [
    "La función plot aplicada al objeto de cv.glmnet nos muestra un gráfico con los valores de lambda y el error cuadrático medio en el eje y. En este caso se muestra que si incrementamos la penalización el error se va incrementando.\n",
    "\n",
    "Para predecir los valores volvemos a usar la función predict solo que en este caso le debemos pasar el argumento \"s\", que se refiere al valor de lambda por el cual queremos estimar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d03d567-25a0-4b6a-a09e-185bc2fe7a86",
   "metadata": {
    "executionInfo": {
     "elapsed": 340601,
     "status": "aborted",
     "timestamp": 1653562471922,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "7d03d567-25a0-4b6a-a09e-185bc2fe7a86"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>mse_train</dt><dd>0.202132448150482</dd><dt>mse_test</dt><dd>0.201400236433329</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[mse\\textbackslash{}\\_train] 0.202132448150482\n",
       "\\item[mse\\textbackslash{}\\_test] 0.201400236433329\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "mse_train\n",
       ":   0.202132448150482mse_test\n",
       ":   0.201400236433329\n",
       "\n"
      ],
      "text/plain": [
       "mse_train  mse_test \n",
       "0.2021324 0.2014002 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ridge.pred <- predict(ridge.mod, s= bestlam, newx = (model.matrix(linear, X.test)))\n",
    "ridge.pred.train <- predict(ridge.mod, s=bestlam, newx = model.matrix(linear, X.train))\n",
    "\n",
    "ridge_rdos <- c('mse_train' = mse(ridge.pred.train, y.train), 'mse_test' = mse(ridge.pred, y.test))\n",
    "ridge_rdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2c4d080-e71d-4f99-8d3c-6e1da5199afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>f1:</strong> 0.511314306825529"
      ],
      "text/latex": [
       "\\textbf{f1:} 0.511314306825529"
      ],
      "text/markdown": [
       "**f1:** 0.511314306825529"
      ],
      "text/plain": [
       "       f1 \n",
       "0.5113143 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# aplciamos clasificación\n",
    "clas <- clasif(ridge.pred, 0.3)\n",
    "ridge_rdos['f1'] <- f1_score(clas, y.test)\n",
    "ridge_rdos['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81daae65-d174-4059-a84a-86ea263b4ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 3 × 4 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>ols_rdos</th><th scope=col>logit_rdos</th><th scope=col>svm_rdos</th><th scope=col>ridge_rdos</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>mse_train</th><td>0.2019455</td><td>0.2019257</td><td>0.2019455</td><td>0.2021324</td></tr>\n",
       "\t<tr><th scope=row>mse_test</th><td>0.2012196</td><td>0.2014333</td><td>0.2012196</td><td>0.2014002</td></tr>\n",
       "\t<tr><th scope=row>f1</th><td>0.5095327</td><td>0.5027429</td><td>0.5095327</td><td>0.5113143</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 4 of type dbl\n",
       "\\begin{tabular}{r|llll}\n",
       "  & ols\\_rdos & logit\\_rdos & svm\\_rdos & ridge\\_rdos\\\\\n",
       "\\hline\n",
       "\tmse\\_train & 0.2019455 & 0.2019257 & 0.2019455 & 0.2021324\\\\\n",
       "\tmse\\_test & 0.2012196 & 0.2014333 & 0.2012196 & 0.2014002\\\\\n",
       "\tf1 & 0.5095327 & 0.5027429 & 0.5095327 & 0.5113143\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 4 of type dbl\n",
       "\n",
       "| <!--/--> | ols_rdos | logit_rdos | svm_rdos | ridge_rdos |\n",
       "|---|---|---|---|---|\n",
       "| mse_train | 0.2019455 | 0.2019257 | 0.2019455 | 0.2021324 |\n",
       "| mse_test | 0.2012196 | 0.2014333 | 0.2012196 | 0.2014002 |\n",
       "| f1 | 0.5095327 | 0.5027429 | 0.5095327 | 0.5113143 |\n",
       "\n"
      ],
      "text/plain": [
       "          ols_rdos  logit_rdos svm_rdos  ridge_rdos\n",
       "mse_train 0.2019455 0.2019257  0.2019455 0.2021324 \n",
       "mse_test  0.2012196 0.2014333  0.2012196 0.2014002 \n",
       "f1        0.5095327 0.5027429  0.5095327 0.5113143 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rdos <- cbind(rdos, ridge_rdos)\n",
    "rdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60c184e6-84b1-4b02-bff0-782b642ee5dd",
   "metadata": {
    "executionInfo": {
     "elapsed": 340597,
     "status": "aborted",
     "timestamp": 1653562471923,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "60c184e6-84b1-4b02-bff0-782b642ee5dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35 x 1 sparse Matrix of class \"dgCMatrix\"\n",
       "                                    s1\n",
       "(Intercept)               0.3184022756\n",
       "(Intercept)               .           \n",
       "yob                      -0.0260589120\n",
       "hh_size                   0.0051772359\n",
       "sex                      -0.0043684285\n",
       "city                      0.0384384809\n",
       "g2000                    -0.0064590779\n",
       "g2002                     0.0281784997\n",
       "p2000                     0.0342361034\n",
       "p2002                     0.0516700494\n",
       "p2004                     0.0672946573\n",
       "totalpopulation_estimate  0.0079586708\n",
       "percent_male             -0.0032137090\n",
       "median_age                0.0054647061\n",
       "percent_62yearsandover    0.0036362456\n",
       "percent_white             0.0085212063\n",
       "percent_black             0.0078908661\n",
       "median_income             0.0146987121\n",
       "employ_20to64            -0.0116581171\n",
       "highschool                0.0127484396\n",
       "bach_orhigher            -0.0032986286\n",
       "percent_hispanicorlatino -0.0017423180\n",
       "noise1                   -0.0002216600\n",
       "noise2                    0.0005995435\n",
       "noise3                   -0.0023031111\n",
       "noise4                   -0.0021870293\n",
       "noise5                   -0.0008989118\n",
       "noise6                    0.0022365450\n",
       "noise7                    0.0004353775\n",
       "noise8                    0.0011305628\n",
       "noise9                   -0.0004479132\n",
       "noise10                   0.0008822160\n",
       "noise11                   0.0002807225\n",
       "noise12                  -0.0001615805\n",
       "noise13                   0.0011130831"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# si queremos ver los coeficientes hay que agregar el argumento \"coefficients\"\n",
    "predict(ridge.mod, type = \"coefficients\", s = bestlam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0258e068-1803-4d65-82f3-65fdf7266573",
   "metadata": {
    "id": "0258e068-1803-4d65-82f3-65fdf7266573"
   },
   "source": [
    "### LASSO\n",
    "\n",
    "La regresión LASSO es muy similar a la ridge, la diferencia es que se cambia la penalización $L2$ por la penalización $L1$. \n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\beta}^{lasso} = argmin_β\\left(y_i-\\beta_0-\\sum_{j=1}^p\\beta_j^2\\right)^2\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "sujeto\\ a\\ \\sum_{j=1}^p|\\beta_j|\\ <= t\n",
    "\\end{equation}\n",
    "\n",
    "Resolviendo el problema el estimador nos queda de la siguiente forma:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\beta}^{lasso} = argmin_β\\left\\{\\left(y_i-\\beta_0-\\sum_{j=1}^p\\beta_j^2\\right)^2 + λ\\sum_{j=1}^p|\\beta_j|\\right\\}\n",
    "\\end{equation}\n",
    "\n",
    "La restricción de esta regresión lleva los parametros $\\beta$ hacia 0 anulando los que no son relevantes para la solución del problema, a diferencia de la ridge que se acerca a 0 asintóticamente. Esta regresión es muy útil para la selección de variables es por eso que ultimamente es más utilizada que la ridge. \n",
    "\n",
    "Como ya había mencionado la función para calcular lasso es la misma que la de ridge, solo que ahora se le cambia el parámetro alpha y se pone en valor 1. Lo demás funciona de la mísma manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9773f9a-f859-4c30-97e3-1cd45f18da2b",
   "metadata": {
    "executionInfo": {
     "elapsed": 340589,
     "status": "aborted",
     "timestamp": 1653562471923,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "b9773f9a-f859-4c30-97e3-1cd45f18da2b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in regularize.values(x, y, ties, missing(ties), na.rm = na.rm):\n",
      "\"collapsing to unique 'x' values\"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAP1BMVEUAAAAil+Yo4uVNTU1h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\nSICA/wNwl8qiQOIU+gAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso.mod <- glmnet(model.matrix(linear, X.train), y.train, alpha = 1, lambda = grid)\n",
    "plot(lasso.mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be301e63-5054-4055-9085-d4b2d2c83458",
   "metadata": {
    "executionInfo": {
     "elapsed": 340587,
     "status": "aborted",
     "timestamp": 1653562471926,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "be301e63-5054-4055-9085-d4b2d2c83458"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.000326791214339085"
      ],
      "text/latex": [
       "0.000326791214339085"
      ],
      "text/markdown": [
       "0.000326791214339085"
      ],
      "text/plain": [
       "[1] 0.0003267912"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>mse_train</dt><dd>0.201957691657874</dd><dt>mse_test</dt><dd>0.201219171102631</dd><dt>f1</dt><dd>0.510586699001959</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[mse\\textbackslash{}\\_train] 0.201957691657874\n",
       "\\item[mse\\textbackslash{}\\_test] 0.201219171102631\n",
       "\\item[f1] 0.510586699001959\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "mse_train\n",
       ":   0.201957691657874mse_test\n",
       ":   0.201219171102631f1\n",
       ":   0.510586699001959\n",
       "\n"
      ],
      "text/plain": [
       "mse_train  mse_test        f1 \n",
       "0.2019577 0.2012192 0.5105867 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(154)\n",
    "#X.train <- model.matrix(linear, as.data.frame(X.train))\n",
    "#X.test <- model.matrix(linear, as.data.frame(X.test))\n",
    "cv_lasso <- cv.glmnet(model.matrix(linear,X.train), y.train, alpha = 1)\n",
    "plot(cv_lasso)\n",
    "bestlam <- cv_lasso$lambda.min\n",
    "bestlam\n",
    "\n",
    "lasso.pred <- predict(cv_lasso, s= bestlam, newx = model.matrix(linear,X.test))\n",
    "lasso.pred.train <- predict(cv_lasso, s= bestlam, newx = model.matrix(linear,X.train))\n",
    "clas <- clasif(lasso.pred, 0.3)\n",
    "\n",
    "lasso_rdos <- c('mse_train' = mse(lasso.pred.train, y.train), 'mse_test' = mse(lasso.pred, y.test), 'f1' = f1_score(clas, y.test))\n",
    "lasso_rdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52a6d5bf-a9b0-40ff-8f65-aed01d09f690",
   "metadata": {
    "executionInfo": {
     "elapsed": 340584,
     "status": "aborted",
     "timestamp": 1653562471928,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "52a6d5bf-a9b0-40ff-8f65-aed01d09f690"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35 x 1 sparse Matrix of class \"dgCMatrix\"\n",
       "                                    s1\n",
       "(Intercept)               3.183872e-01\n",
       "(Intercept)               .           \n",
       "yob                      -2.816626e-02\n",
       "hh_size                   7.156824e-03\n",
       "sex                      -4.172734e-03\n",
       "city                      4.293234e-02\n",
       "g2000                    -8.825061e-03\n",
       "g2002                     2.936918e-02\n",
       "p2000                     3.743254e-02\n",
       "p2002                     5.675968e-02\n",
       "p2004                     7.498304e-02\n",
       "totalpopulation_estimate  1.022712e-02\n",
       "percent_male             -3.709430e-03\n",
       "median_age                2.788469e-03\n",
       "percent_62yearsandover    6.241068e-03\n",
       "percent_white             1.488301e-02\n",
       "percent_black             1.365543e-02\n",
       "median_income             2.362776e-02\n",
       "employ_20to64            -1.283373e-02\n",
       "highschool                2.201891e-02\n",
       "bach_orhigher             .           \n",
       "percent_hispanicorlatino  .           \n",
       "noise1                    .           \n",
       "noise2                    2.638516e-04\n",
       "noise3                   -2.214100e-03\n",
       "noise4                   -2.041656e-03\n",
       "noise5                   -6.094112e-04\n",
       "noise6                    2.112031e-03\n",
       "noise7                    1.763937e-04\n",
       "noise8                    8.916539e-04\n",
       "noise9                   -1.420510e-04\n",
       "noise10                   6.669624e-04\n",
       "noise11                   4.860416e-05\n",
       "noise12                   .           \n",
       "noise13                   8.374545e-04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(cv_lasso, type = \"coefficients\", s = bestlam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "784fbcc9-5866-43dd-b9ac-a077618d545e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 3 × 5 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>ols_rdos</th><th scope=col>logit_rdos</th><th scope=col>svm_rdos</th><th scope=col>ridge_rdos</th><th scope=col>lasso_rdos</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>mse_train</th><td>0.2019455</td><td>0.2019257</td><td>0.2019455</td><td>0.2021324</td><td>0.2019577</td></tr>\n",
       "\t<tr><th scope=row>mse_test</th><td>0.2012196</td><td>0.2014333</td><td>0.2012196</td><td>0.2014002</td><td>0.2012192</td></tr>\n",
       "\t<tr><th scope=row>f1</th><td>0.5095327</td><td>0.5027429</td><td>0.5095327</td><td>0.5113143</td><td>0.5105867</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 5 of type dbl\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & ols\\_rdos & logit\\_rdos & svm\\_rdos & ridge\\_rdos & lasso\\_rdos\\\\\n",
       "\\hline\n",
       "\tmse\\_train & 0.2019455 & 0.2019257 & 0.2019455 & 0.2021324 & 0.2019577\\\\\n",
       "\tmse\\_test & 0.2012196 & 0.2014333 & 0.2012196 & 0.2014002 & 0.2012192\\\\\n",
       "\tf1 & 0.5095327 & 0.5027429 & 0.5095327 & 0.5113143 & 0.5105867\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 5 of type dbl\n",
       "\n",
       "| <!--/--> | ols_rdos | logit_rdos | svm_rdos | ridge_rdos | lasso_rdos |\n",
       "|---|---|---|---|---|---|\n",
       "| mse_train | 0.2019455 | 0.2019257 | 0.2019455 | 0.2021324 | 0.2019577 |\n",
       "| mse_test | 0.2012196 | 0.2014333 | 0.2012196 | 0.2014002 | 0.2012192 |\n",
       "| f1 | 0.5095327 | 0.5027429 | 0.5095327 | 0.5113143 | 0.5105867 |\n",
       "\n"
      ],
      "text/plain": [
       "          ols_rdos  logit_rdos svm_rdos  ridge_rdos lasso_rdos\n",
       "mse_train 0.2019455 0.2019257  0.2019455 0.2021324  0.2019577 \n",
       "mse_test  0.2012196 0.2014333  0.2012196 0.2014002  0.2012192 \n",
       "f1        0.5095327 0.5027429  0.5095327 0.5113143  0.5105867 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rdos <- cbind(rdos, lasso_rdos)\n",
    "rdos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c4d469-669e-4e07-bf51-df936077c684",
   "metadata": {},
   "source": [
    "Otro argumento de salida que ofrece glmnet es \"lambda.1se\" este no es el mínimo lambda es pero es el valor que más regulariza y se encuentra dentro del error estandard del mínimo. Se suele utilizar mucho porque a los efectos de seleccionar variables es más estricto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41e96c79-1a73-42f8-abab-5bc3c57a4482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>mse_train</dt><dd>0.202293626323213</dd><dt>mse_test</dt><dd>0.201374201850021</dd><dt>f1</dt><dd>0.510053495665006</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[mse\\textbackslash{}\\_train] 0.202293626323213\n",
       "\\item[mse\\textbackslash{}\\_test] 0.201374201850021\n",
       "\\item[f1] 0.510053495665006\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "mse_train\n",
       ":   0.202293626323213mse_test\n",
       ":   0.201374201850021f1\n",
       ":   0.510053495665006\n",
       "\n"
      ],
      "text/plain": [
       "mse_train  mse_test        f1 \n",
       "0.2022936 0.2013742 0.5100535 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso.pred2 <- predict(cv_lasso, s= cv_lasso$lambda.1se, newx = model.matrix(linear,X.test))\n",
    "lasso.pred2.train <- predict(cv_lasso, s= cv_lasso$lambda.1se, newx = model.matrix(linear,X.train))\n",
    "clas <- clasif(lasso.pred2, 0.3)\n",
    "\n",
    "lasso2_rdos <- c('mse_train' = mse(lasso.pred2.train, y.train), 'mse_test' = mse(lasso.pred2, y.test), 'f1' = f1_score(clas, y.test))\n",
    "lasso2_rdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a84b1311-fa7c-432e-b561-cc0bc2240075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 3 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>ols_rdos</th><th scope=col>logit_rdos</th><th scope=col>svm_rdos</th><th scope=col>ridge_rdos</th><th scope=col>lasso_rdos</th><th scope=col>lasso2_rdos</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>mse_train</th><td>0.2019455</td><td>0.2019257</td><td>0.2019455</td><td>0.2021324</td><td>0.2019577</td><td>0.2022936</td></tr>\n",
       "\t<tr><th scope=row>mse_test</th><td>0.2012196</td><td>0.2014333</td><td>0.2012196</td><td>0.2014002</td><td>0.2012192</td><td>0.2013742</td></tr>\n",
       "\t<tr><th scope=row>f1</th><td>0.5095327</td><td>0.5027429</td><td>0.5095327</td><td>0.5113143</td><td>0.5105867</td><td>0.5100535</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & ols\\_rdos & logit\\_rdos & svm\\_rdos & ridge\\_rdos & lasso\\_rdos & lasso2\\_rdos\\\\\n",
       "\\hline\n",
       "\tmse\\_train & 0.2019455 & 0.2019257 & 0.2019455 & 0.2021324 & 0.2019577 & 0.2022936\\\\\n",
       "\tmse\\_test & 0.2012196 & 0.2014333 & 0.2012196 & 0.2014002 & 0.2012192 & 0.2013742\\\\\n",
       "\tf1 & 0.5095327 & 0.5027429 & 0.5095327 & 0.5113143 & 0.5105867 & 0.5100535\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | ols_rdos | logit_rdos | svm_rdos | ridge_rdos | lasso_rdos | lasso2_rdos |\n",
       "|---|---|---|---|---|---|---|\n",
       "| mse_train | 0.2019455 | 0.2019257 | 0.2019455 | 0.2021324 | 0.2019577 | 0.2022936 |\n",
       "| mse_test | 0.2012196 | 0.2014333 | 0.2012196 | 0.2014002 | 0.2012192 | 0.2013742 |\n",
       "| f1 | 0.5095327 | 0.5027429 | 0.5095327 | 0.5113143 | 0.5105867 | 0.5100535 |\n",
       "\n"
      ],
      "text/plain": [
       "          ols_rdos  logit_rdos svm_rdos  ridge_rdos lasso_rdos lasso2_rdos\n",
       "mse_train 0.2019455 0.2019257  0.2019455 0.2021324  0.2019577  0.2022936  \n",
       "mse_test  0.2012196 0.2014333  0.2012196 0.2014002  0.2012192  0.2013742  \n",
       "f1        0.5095327 0.5027429  0.5095327 0.5113143  0.5105867  0.5100535  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rdos <- cbind(rdos, lasso2_rdos)\n",
    "rdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0250eb2-2393-4ffb-a6ab-af24604f66d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35 x 1 sparse Matrix of class \"dgCMatrix\"\n",
       "                                    s1\n",
       "(Intercept)               0.3184102134\n",
       "(Intercept)               .           \n",
       "yob                      -0.0249206744\n",
       "hh_size                   0.0035385429\n",
       "sex                      -0.0021181861\n",
       "city                      0.0389276178\n",
       "g2000                    -0.0044323692\n",
       "g2002                     0.0268710977\n",
       "p2000                     0.0348893771\n",
       "p2002                     0.0548121692\n",
       "p2004                     0.0712812422\n",
       "totalpopulation_estimate  0.0021933249\n",
       "percent_male              .           \n",
       "median_age                0.0065279892\n",
       "percent_62yearsandover    .           \n",
       "percent_white             0.0005478882\n",
       "percent_black             .           \n",
       "median_income             0.0032295022\n",
       "employ_20to64            -0.0093657030\n",
       "highschool                0.0054411236\n",
       "bach_orhigher             .           \n",
       "percent_hispanicorlatino -0.0013336100\n",
       "noise1                    .           \n",
       "noise2                    .           \n",
       "noise3                    .           \n",
       "noise4                    .           \n",
       "noise5                    .           \n",
       "noise6                    .           \n",
       "noise7                    .           \n",
       "noise8                    .           \n",
       "noise9                    .           \n",
       "noise10                   .           \n",
       "noise11                   .           \n",
       "noise12                   .           \n",
       "noise13                   .           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(cv_lasso, type = \"coefficients\",s = cv_lasso$lambda.1se)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833e5cfe-7fa8-4b1f-95db-2711f47b990c",
   "metadata": {
    "id": "833e5cfe-7fa8-4b1f-95db-2711f47b990c"
   },
   "source": [
    "### Ridge y Lasso para una regresión logística\n",
    "\n",
    "Ante el mismo problema de clasificación podemos transformar a ridge o LASSO en una regresión logística agregando el argumento \"family = 'binomial'\" al comando glmnet o cv.glmnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e79993a7-f1c5-4e5e-8d57-fa631a998135",
   "metadata": {
    "executionInfo": {
     "elapsed": 340578,
     "status": "aborted",
     "timestamp": 1653562471931,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "e79993a7-f1c5-4e5e-8d57-fa631a998135"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAP1BMVEUAAAAil+Yo4uVNTU1h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\nkCCAkCDA/wdDoHSdZLhnBQAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ridge.logit <- glmnet(X.train, y.train, alpha = 0, family = 'binomial')\n",
    "plot(ridge.logit, label = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "677e7835-d0fd-4b03-b87a-c684bc3a12f4",
   "metadata": {
    "executionInfo": {
     "elapsed": 340573,
     "status": "aborted",
     "timestamp": 1653562471931,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "677e7835-d0fd-4b03-b87a-c684bc3a12f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in plotCoef(x$beta, lambda = x$lambda, df = x$df, dev = x$dev.ratio, :\n",
      "\"1 or less nonzero coefficients; glmnet plot is not meaningful\"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nB+uKYKedm8ogAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso.logit <- glmnet(X.train, y.train, alpha = 1, family = 'binomial')\n",
    "plot(lasso.logit, label = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f74caa-f32e-4be3-b403-ba3b8f8fde02",
   "metadata": {
    "id": "54f74caa-f32e-4be3-b403-ba3b8f8fde02"
   },
   "source": [
    "podemos obtener los coeficientes para uno o mas valoresd e $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de6dd1c9-a613-4f03-9521-9c725cd25059",
   "metadata": {
    "executionInfo": {
     "elapsed": 340568,
     "status": "aborted",
     "timestamp": 1653562471932,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "de6dd1c9-a613-4f03-9521-9c725cd25059"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36 x 2 sparse Matrix of class \"dgCMatrix\"\n",
       "                                s1        s2\n",
       "(Intercept)              -3.721355 -5.337852\n",
       "Y                         6.654074  9.909548\n",
       "W                         .         .       \n",
       "yob                       .         .       \n",
       "hh_size                   .         .       \n",
       "sex                       .         .       \n",
       "city                      .         .       \n",
       "g2000                     .         .       \n",
       "g2002                     .         .       \n",
       "p2000                     .         .       \n",
       "p2002                     .         .       \n",
       "p2004                     .         .       \n",
       "totalpopulation_estimate  .         .       \n",
       "percent_male              .         .       \n",
       "median_age                .         .       \n",
       "percent_62yearsandover    .         .       \n",
       "percent_white             .         .       \n",
       "percent_black             .         .       \n",
       "median_income             .         .       \n",
       "employ_20to64             .         .       \n",
       "highschool                .         .       \n",
       "bach_orhigher             .         .       \n",
       "percent_hispanicorlatino  .         .       \n",
       "noise1                    .         .       \n",
       "noise2                    .         .       \n",
       "noise3                    .         .       \n",
       "noise4                    .         .       \n",
       "noise5                    .         .       \n",
       "noise6                    .         .       \n",
       "noise7                    .         .       \n",
       "noise8                    .         .       \n",
       "noise9                    .         .       \n",
       "noise10                   .         .       \n",
       "noise11                   .         .       \n",
       "noise12                   .         .       \n",
       "noise13                   .         .       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef(lasso.logit, s = c(0.03457, 0.007))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c4c0e0d-87c3-4032-ab2b-ce9e64e84bf7",
   "metadata": {
    "executionInfo": {
     "elapsed": 340567,
     "status": "aborted",
     "timestamp": 1653562471933,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "9c4c0e0d-87c3-4032-ab2b-ce9e64e84bf7"
   },
   "outputs": [],
   "source": [
    "pre.lasso.logit <- predict(lasso.logit, newx = as.matrix( X.test), \n",
    "                   s = c(0.03457, 0.007), type = \"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82285d83-e995-4dcc-afd6-970a23561c34",
   "metadata": {
    "executionInfo": {
     "elapsed": 340562,
     "status": "aborted",
     "timestamp": 1653562471933,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "82285d83-e995-4dcc-afd6-970a23561c34"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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\nCAkQ8B9Y9t0l6gkwSwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#usamos cross validation\n",
    "cv.glm.logit <- cv.glmnet(model.matrix(linear,X.train), y.train, alpha = 1, family = 'binomial')\n",
    "plot(cv.glm.logit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "895c1e35-738e-4e9d-bcaa-b8f0a3a6368d",
   "metadata": {
    "executionInfo": {
     "elapsed": 340558,
     "status": "aborted",
     "timestamp": 1653562471934,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "895c1e35-738e-4e9d-bcaa-b8f0a3a6368d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35 x 1 sparse Matrix of class \"dgCMatrix\"\n",
       "                                   s1\n",
       "(Intercept)              -0.815605015\n",
       "(Intercept)               .          \n",
       "yob                      -0.122287335\n",
       "hh_size                   .          \n",
       "sex                      -0.004410615\n",
       "city                      0.173216751\n",
       "g2000                     .          \n",
       "g2002                     0.149877166\n",
       "p2000                     0.158145980\n",
       "p2002                     0.256773517\n",
       "p2004                     0.338156130\n",
       "totalpopulation_estimate  .          \n",
       "percent_male              .          \n",
       "median_age                0.027876934\n",
       "percent_62yearsandover    .          \n",
       "percent_white             .          \n",
       "percent_black             .          \n",
       "median_income             .          \n",
       "employ_20to64            -0.039573571\n",
       "highschool                0.006640390\n",
       "bach_orhigher             .          \n",
       "percent_hispanicorlatino -0.003735525\n",
       "noise1                    .          \n",
       "noise2                    .          \n",
       "noise3                    .          \n",
       "noise4                    .          \n",
       "noise5                    .          \n",
       "noise6                    .          \n",
       "noise7                    .          \n",
       "noise8                    .          \n",
       "noise9                    .          \n",
       "noise10                   .          \n",
       "noise11                   .          \n",
       "noise12                   .          \n",
       "noise13                   .          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bestlam <- cv.glm.logit$lambda.1se\n",
    "coef(cv.glm.logit, s = bestlam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5dd7f266-d3d8-4c04-9b8e-fcf2a909fc3b",
   "metadata": {
    "executionInfo": {
     "elapsed": 340556,
     "status": "aborted",
     "timestamp": 1653562471934,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "5dd7f266-d3d8-4c04-9b8e-fcf2a909fc3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in pred - y_test:\n",
      "\"longitud de objeto mayor no es múltiplo de la longitud de uno menor\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>mse_train</dt><dd>0.229829349865633</dd><dt>mse_test</dt><dd>0.201666208479141</dd><dt>f1</dt><dd>0.504658534242628</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[mse\\textbackslash{}\\_train] 0.229829349865633\n",
       "\\item[mse\\textbackslash{}\\_test] 0.201666208479141\n",
       "\\item[f1] 0.504658534242628\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "mse_train\n",
       ":   0.229829349865633mse_test\n",
       ":   0.201666208479141f1\n",
       ":   0.504658534242628\n",
       "\n"
      ],
      "text/plain": [
       "mse_train  mse_test        f1 \n",
       "0.2298293 0.2016662 0.5046585 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pre.cv.glm.logit <- as.vector(predict(cv.glm.logit, newx = model.matrix(linear,X.test), s = bestlam, type = \"response\" ))\n",
    "pre.cv.glm.train <- as.vector(predict(cv.glm.logit, newx = model.matrix(linear,X.test), s = bestlam,type = \"response\"))\n",
    "pre.lasso.logit <- clasif(pre.cv.glm.logit,0.3)\n",
    "#predict(cv.glm.logit, newx = model.matrix(linear,X.test), s = bestlam, type = 'class')\n",
    "\n",
    "lasso_logit_rdos <- c('mse_train' = mse(pre.cv.glm.train,y.train), 'mse_test' = mse(pre.cv.glm.logit, y.test), 'f1' = f1_score(pre.lasso.logit, y.test))\n",
    "lasso_logit_rdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b69c32f8-330d-44aa-a871-3a38b9f55773",
   "metadata": {
    "executionInfo": {
     "elapsed": 340554,
     "status": "aborted",
     "timestamp": 1653562471934,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "b69c32f8-330d-44aa-a871-3a38b9f55773"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 3 × 7 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>ols_rdos</th><th scope=col>logit_rdos</th><th scope=col>svm_rdos</th><th scope=col>ridge_rdos</th><th scope=col>lasso_rdos</th><th scope=col>lasso2_rdos</th><th scope=col>lasso_logit_rdos</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>mse_train</th><td>0.2019455</td><td>0.2019257</td><td>0.2019455</td><td>0.2021324</td><td>0.2019577</td><td>0.2022936</td><td>0.2298293</td></tr>\n",
       "\t<tr><th scope=row>mse_test</th><td>0.2012196</td><td>0.2014333</td><td>0.2012196</td><td>0.2014002</td><td>0.2012192</td><td>0.2013742</td><td>0.2016662</td></tr>\n",
       "\t<tr><th scope=row>f1</th><td>0.5095327</td><td>0.5027429</td><td>0.5095327</td><td>0.5113143</td><td>0.5105867</td><td>0.5100535</td><td>0.5046585</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 7 of type dbl\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & ols\\_rdos & logit\\_rdos & svm\\_rdos & ridge\\_rdos & lasso\\_rdos & lasso2\\_rdos & lasso\\_logit\\_rdos\\\\\n",
       "\\hline\n",
       "\tmse\\_train & 0.2019455 & 0.2019257 & 0.2019455 & 0.2021324 & 0.2019577 & 0.2022936 & 0.2298293\\\\\n",
       "\tmse\\_test & 0.2012196 & 0.2014333 & 0.2012196 & 0.2014002 & 0.2012192 & 0.2013742 & 0.2016662\\\\\n",
       "\tf1 & 0.5095327 & 0.5027429 & 0.5095327 & 0.5113143 & 0.5105867 & 0.5100535 & 0.5046585\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 7 of type dbl\n",
       "\n",
       "| <!--/--> | ols_rdos | logit_rdos | svm_rdos | ridge_rdos | lasso_rdos | lasso2_rdos | lasso_logit_rdos |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| mse_train | 0.2019455 | 0.2019257 | 0.2019455 | 0.2021324 | 0.2019577 | 0.2022936 | 0.2298293 |\n",
       "| mse_test | 0.2012196 | 0.2014333 | 0.2012196 | 0.2014002 | 0.2012192 | 0.2013742 | 0.2016662 |\n",
       "| f1 | 0.5095327 | 0.5027429 | 0.5095327 | 0.5113143 | 0.5105867 | 0.5100535 | 0.5046585 |\n",
       "\n"
      ],
      "text/plain": [
       "          ols_rdos  logit_rdos svm_rdos  ridge_rdos lasso_rdos lasso2_rdos\n",
       "mse_train 0.2019455 0.2019257  0.2019455 0.2021324  0.2019577  0.2022936  \n",
       "mse_test  0.2012196 0.2014333  0.2012196 0.2014002  0.2012192  0.2013742  \n",
       "f1        0.5095327 0.5027429  0.5095327 0.5113143  0.5105867  0.5100535  \n",
       "          lasso_logit_rdos\n",
       "mse_train 0.2298293       \n",
       "mse_test  0.2016662       \n",
       "f1        0.5046585       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rdos <- cbind(rdos, lasso_logit_rdos)\n",
    "rdos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f67092a-f1f8-44c7-90d2-238924b31a41",
   "metadata": {
    "id": "4f67092a-f1f8-44c7-90d2-238924b31a41"
   },
   "source": [
    "### Elastic net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58563688-deef-470d-af45-ce64f44d89d9",
   "metadata": {},
   "source": [
    "El método *elastic net* junta las penalizaciones $L1$ y $L2$ en un solo algoritmo. La fórmula del estimador quedaría de la siguiente forma:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\beta}^{en} = argmin_β\\left\\{\\left(y_i-\\beta_0-\\sum_{j=1}^p\\beta_j^2\\right)^2 + (1-\\alpha) λ\\sum_{j=1}^p\\beta_j^2+\\alpha\\lambda\\sum_{j=1}^p|\\beta_j|\\right\\}\n",
    "\\end{equation}\n",
    "\n",
    "Es muy similar a los anteriores solo que ajusta con un parámetro $\\alpha$ a cual penalización le da más importancia, LASSO y ridge son casos particulares de elastic net cuando $\\alpha = 1$ y cuando $\\alpha = 0$ respectivamente.\n",
    "\n",
    "De esta misma forma se trabaja en R, con la misma función glmnet salvo que ahora el parámetro alpha va estar dentro del intérvalo $(0,1)$. Siendo todo lo demás igual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c975e83d-f057-4a56-9ace-e2b6cb025e76",
   "metadata": {
    "executionInfo": {
     "elapsed": 340553,
     "status": "aborted",
     "timestamp": 1653562471935,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "c975e83d-f057-4a56-9ace-e2b6cb025e76"
   },
   "outputs": [],
   "source": [
    "elastnet.reg <- glmnet( X.train, y.train, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ed710a0-b130-467a-ba5e-db2aac2a20b6",
   "metadata": {
    "executionInfo": {
     "elapsed": 340549,
     "status": "aborted",
     "timestamp": 1653562471935,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "8ed710a0-b130-467a-ba5e-db2aac2a20b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in plotCoef(x$beta, lambda = x$lambda, df = x$df, dev = x$dev.ratio, :\n",
      "\"1 or less nonzero coefficients; glmnet plot is not meaningful\"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyM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\nDzsdjAT8f3FnAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(elastnet.reg, xvar = \"lambda\", label = FALSE)\n",
    "grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90b3def-c5e1-471c-84c1-0fb09284e1b3",
   "metadata": {},
   "source": [
    "La función cv.glmnet no aplica cross-validation sobre el parámetro alpha por lo tanos eso se debe hacer probando varios coeficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e30cfb39-bbf1-43f1-bc80-92072beb0911",
   "metadata": {
    "executionInfo": {
     "elapsed": 340545,
     "status": "aborted",
     "timestamp": 1653562471936,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "e30cfb39-bbf1-43f1-bc80-92072beb0911"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>mse_train</dt><dd>0.202441699842654</dd><dt>mse_test</dt><dd>0.201673347512014</dd><dt>f1</dt><dd>0.504511422537915</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[mse\\textbackslash{}\\_train] 0.202441699842654\n",
       "\\item[mse\\textbackslash{}\\_test] 0.201673347512014\n",
       "\\item[f1] 0.504511422537915\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "mse_train\n",
       ":   0.202441699842654mse_test\n",
       ":   0.201673347512014f1\n",
       ":   0.504511422537915\n",
       "\n"
      ],
      "text/plain": [
       "mse_train  mse_test        f1 \n",
       "0.2024417 0.2016733 0.5045114 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "elastnet.logit <- cv.glmnet( model.matrix(linear,X.train), y.train, alpha = 0.8, family = 'binomial')\n",
    "optlambda <- elastnet.logit$lambda.1se\n",
    "\n",
    "pre.elastnet <- as.vector(predict(elastnet.logit, newx = model.matrix(linear,X.test), s = optlambda, type = \"response\" ))\n",
    "pre.elastnet.train <- as.vector(predict(elastnet.logit, newx = model.matrix(linear,X.train), s = optlambda,type = \"response\"))\n",
    "pre.elastnet.logit <- clasif(pre.elastnet,0.3)\n",
    "\n",
    "elastnet_logit_rdos <- c('mse_train' = mse(pre.elastnet.train,y.train), 'mse_test' = mse(pre.elastnet, y.test), 'f1' = f1_score(pre.elastnet.logit, y.test))\n",
    "elastnet_logit_rdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "62f6a60d-217c-4358-af3b-0c75f7ca2f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 3 × 8 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>ols_rdos</th><th scope=col>logit_rdos</th><th scope=col>svm_rdos</th><th scope=col>ridge_rdos</th><th scope=col>lasso_rdos</th><th scope=col>lasso2_rdos</th><th scope=col>lasso_logit_rdos</th><th scope=col>elastnet_logit_rdos</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>mse_train</th><td>0.2019455</td><td>0.2019257</td><td>0.2019455</td><td>0.2021324</td><td>0.2019577</td><td>0.2022936</td><td>0.2298293</td><td>0.2024417</td></tr>\n",
       "\t<tr><th scope=row>mse_test</th><td>0.2012196</td><td>0.2014333</td><td>0.2012196</td><td>0.2014002</td><td>0.2012192</td><td>0.2013742</td><td>0.2016662</td><td>0.2016733</td></tr>\n",
       "\t<tr><th scope=row>f1</th><td>0.5095327</td><td>0.5027429</td><td>0.5095327</td><td>0.5113143</td><td>0.5105867</td><td>0.5100535</td><td>0.5046585</td><td>0.5045114</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 8 of type dbl\n",
       "\\begin{tabular}{r|llllllll}\n",
       "  & ols\\_rdos & logit\\_rdos & svm\\_rdos & ridge\\_rdos & lasso\\_rdos & lasso2\\_rdos & lasso\\_logit\\_rdos & elastnet\\_logit\\_rdos\\\\\n",
       "\\hline\n",
       "\tmse\\_train & 0.2019455 & 0.2019257 & 0.2019455 & 0.2021324 & 0.2019577 & 0.2022936 & 0.2298293 & 0.2024417\\\\\n",
       "\tmse\\_test & 0.2012196 & 0.2014333 & 0.2012196 & 0.2014002 & 0.2012192 & 0.2013742 & 0.2016662 & 0.2016733\\\\\n",
       "\tf1 & 0.5095327 & 0.5027429 & 0.5095327 & 0.5113143 & 0.5105867 & 0.5100535 & 0.5046585 & 0.5045114\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 8 of type dbl\n",
       "\n",
       "| <!--/--> | ols_rdos | logit_rdos | svm_rdos | ridge_rdos | lasso_rdos | lasso2_rdos | lasso_logit_rdos | elastnet_logit_rdos |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| mse_train | 0.2019455 | 0.2019257 | 0.2019455 | 0.2021324 | 0.2019577 | 0.2022936 | 0.2298293 | 0.2024417 |\n",
       "| mse_test | 0.2012196 | 0.2014333 | 0.2012196 | 0.2014002 | 0.2012192 | 0.2013742 | 0.2016662 | 0.2016733 |\n",
       "| f1 | 0.5095327 | 0.5027429 | 0.5095327 | 0.5113143 | 0.5105867 | 0.5100535 | 0.5046585 | 0.5045114 |\n",
       "\n"
      ],
      "text/plain": [
       "          ols_rdos  logit_rdos svm_rdos  ridge_rdos lasso_rdos lasso2_rdos\n",
       "mse_train 0.2019455 0.2019257  0.2019455 0.2021324  0.2019577  0.2022936  \n",
       "mse_test  0.2012196 0.2014333  0.2012196 0.2014002  0.2012192  0.2013742  \n",
       "f1        0.5095327 0.5027429  0.5095327 0.5113143  0.5105867  0.5100535  \n",
       "          lasso_logit_rdos elastnet_logit_rdos\n",
       "mse_train 0.2298293        0.2024417          \n",
       "mse_test  0.2016662        0.2016733          \n",
       "f1        0.5046585        0.5045114          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rdos <- cbind(rdos, elastnet_logit_rdos)\n",
    "rdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "20b1a115-bd68-4d74-83ee-f98a35333630",
   "metadata": {
    "executionInfo": {
     "elapsed": 340534,
     "status": "aborted",
     "timestamp": 1653562471937,
     "user": {
      "displayName": "Pablo Quintana",
      "userId": "00674039532099061635"
     },
     "user_tz": 180
    },
    "id": "20b1a115-bd68-4d74-83ee-f98a35333630"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35 x 1 sparse Matrix of class \"dgCMatrix\"\n",
       "                                    s1\n",
       "(Intercept)              -0.8131202054\n",
       "(Intercept)               .           \n",
       "yob                      -0.1197573140\n",
       "hh_size                   .           \n",
       "sex                      -0.0003716016\n",
       "city                      0.1663460951\n",
       "g2000                     .           \n",
       "g2002                     0.1454205845\n",
       "p2000                     0.1542527256\n",
       "p2002                     0.2525058987\n",
       "p2004                     0.3318767969\n",
       "totalpopulation_estimate  .           \n",
       "percent_male              .           \n",
       "median_age                0.0251260777\n",
       "percent_62yearsandover    .           \n",
       "percent_white             .           \n",
       "percent_black             .           \n",
       "median_income             .           \n",
       "employ_20to64            -0.0380410025\n",
       "highschool                0.0016586280\n",
       "bach_orhigher             .           \n",
       "percent_hispanicorlatino  .           \n",
       "noise1                    .           \n",
       "noise2                    .           \n",
       "noise3                    .           \n",
       "noise4                    .           \n",
       "noise5                    .           \n",
       "noise6                    .           \n",
       "noise7                    .           \n",
       "noise8                    .           \n",
       "noise9                    .           \n",
       "noise10                   .           \n",
       "noise11                   .           \n",
       "noise12                   .           \n",
       "noise13                   .           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef(cv.glm.logit, s = optlambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e430fbc1-bb73-4a40-aa9a-74378a724ffa",
   "metadata": {},
   "source": [
    "### MCO con variables seleccionadas por LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a3c7c323-d727-4b6c-8cbc-71c1268e176e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'yob'</li><li>'hh_size'</li><li>'sex'</li><li>'city'</li><li>'g2000'</li><li>'g2002'</li><li>'p2000'</li><li>'p2002'</li><li>'p2004'</li><li>'totalpopulation_estimate'</li><li>'median_age'</li><li>'percent_white'</li><li>'median_income'</li><li>'employ_20to64'</li><li>'highschool'</li><li>'percent_hispanicorlatino'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'yob'\n",
       "\\item 'hh\\_size'\n",
       "\\item 'sex'\n",
       "\\item 'city'\n",
       "\\item 'g2000'\n",
       "\\item 'g2002'\n",
       "\\item 'p2000'\n",
       "\\item 'p2002'\n",
       "\\item 'p2004'\n",
       "\\item 'totalpopulation\\_estimate'\n",
       "\\item 'median\\_age'\n",
       "\\item 'percent\\_white'\n",
       "\\item 'median\\_income'\n",
       "\\item 'employ\\_20to64'\n",
       "\\item 'highschool'\n",
       "\\item 'percent\\_hispanicorlatino'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'yob'\n",
       "2. 'hh_size'\n",
       "3. 'sex'\n",
       "4. 'city'\n",
       "5. 'g2000'\n",
       "6. 'g2002'\n",
       "7. 'p2000'\n",
       "8. 'p2002'\n",
       "9. 'p2004'\n",
       "10. 'totalpopulation_estimate'\n",
       "11. 'median_age'\n",
       "12. 'percent_white'\n",
       "13. 'median_income'\n",
       "14. 'employ_20to64'\n",
       "15. 'highschool'\n",
       "16. 'percent_hispanicorlatino'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"yob\"                      \"hh_size\"                 \n",
       " [3] \"sex\"                      \"city\"                    \n",
       " [5] \"g2000\"                    \"g2002\"                   \n",
       " [7] \"p2000\"                    \"p2002\"                   \n",
       " [9] \"p2004\"                    \"totalpopulation_estimate\"\n",
       "[11] \"median_age\"               \"percent_white\"           \n",
       "[13] \"median_income\"            \"employ_20to64\"           \n",
       "[15] \"highschool\"               \"percent_hispanicorlatino\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef_lasso <- predict(cv_lasso, type = \"nonzero\") # otra forma de estimar los coeficientes\n",
    "col <-colnames(model.matrix(linear,X.train))\n",
    "sel.var <- col[unlist(coef_lasso)]\n",
    "sel.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cce60408-d4e3-4346-8e08-273aad08ec74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y ~ yob + hh_size + sex + city + g2000 + g2002 + p2000 + p2002 + \n",
       "    p2004 + totalpopulation_estimate + median_age + percent_white + \n",
       "    median_income + employ_20to64 + highschool + percent_hispanicorlatino"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creamos la fórmula con las variables que quedan\n",
    "linear_lasso <- paste('Y', paste(sel.var, collapse = \" + \") , sep = \" ~ \")\n",
    "linear_lasso <- as.formula(linear_lasso)\n",
    "linear_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c19d2e22-d1bf-4d7b-94af-921f4532a65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = linear_lasso, data = X.train)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-0.7699 -0.3381 -0.2185  0.5458  1.0129 \n",
       "\n",
       "Coefficients:\n",
       "                          Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)               0.318390   0.001368 232.746  < 2e-16 ***\n",
       "yob                      -0.028643   0.001507 -19.011  < 2e-16 ***\n",
       "hh_size                   0.007688   0.001447   5.313 1.08e-07 ***\n",
       "sex                      -0.004408   0.001370  -3.218  0.00129 ** \n",
       "city                      0.043364   0.001462  29.652  < 2e-16 ***\n",
       "g2000                    -0.009433   0.001500  -6.287 3.25e-10 ***\n",
       "g2002                     0.029778   0.001502  19.820  < 2e-16 ***\n",
       "p2000                     0.037993   0.001406  27.032  < 2e-16 ***\n",
       "p2002                     0.057121   0.001422  40.163  < 2e-16 ***\n",
       "p2004                     0.075756   0.001400  54.116  < 2e-16 ***\n",
       "totalpopulation_estimate  0.012523   0.001755   7.137 9.62e-13 ***\n",
       "median_age                0.008779   0.001740   5.044 4.56e-07 ***\n",
       "percent_white             0.002715   0.001884   1.441  0.14947    \n",
       "median_income             0.017785   0.002277   7.810 5.76e-15 ***\n",
       "employ_20to64            -0.012729   0.001813  -7.020 2.23e-12 ***\n",
       "highschool                0.020673   0.002565   8.060 7.73e-16 ***\n",
       "percent_hispanicorlatino -0.002054   0.001718  -1.195  0.23199    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.4496 on 107982 degrees of freedom\n",
       "Multiple R-squared:  0.06906,\tAdjusted R-squared:  0.06893 \n",
       "F-statistic: 500.7 on 16 and 107982 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ols_lasso <- lm(linear_lasso, data = X.train)\n",
    "summary(ols_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30dc6fab-5e2c-4562-9964-dca68ab85132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>mse_train</dt><dd>0.20206782970869</dd><dt>mse_test</dt><dd>0.201265172313486</dd><dt>f1</dt><dd>0.508958566629339</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[mse\\textbackslash{}\\_train] 0.20206782970869\n",
       "\\item[mse\\textbackslash{}\\_test] 0.201265172313486\n",
       "\\item[f1] 0.508958566629339\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "mse_train\n",
       ":   0.20206782970869mse_test\n",
       ":   0.201265172313486f1\n",
       ":   0.508958566629339\n",
       "\n"
      ],
      "text/plain": [
       "mse_train  mse_test        f1 \n",
       "0.2020678 0.2012652 0.5089586 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_ols.lasso.train <- predict(ols_lasso, X.train)\n",
    "pred_ols.lasso <- predict(ols_lasso, X.test)\n",
    "clas <- clasif(pred_ols.lasso, 0.3) \n",
    "ols_lasso_rdos <- c('mse_train' = mse(pred_ols.lasso.train, y.train), 'mse_test' = mse(pred_ols.lasso, y.test), 'f1' = f1_score(clas,y.test))\n",
    "ols_lasso_rdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e2c8000d-ef5e-424f-80ec-255bf596e8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 3 × 9 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>ols_rdos</th><th scope=col>logit_rdos</th><th scope=col>svm_rdos</th><th scope=col>ridge_rdos</th><th scope=col>lasso_rdos</th><th scope=col>lasso2_rdos</th><th scope=col>lasso_logit_rdos</th><th scope=col>elastnet_logit_rdos</th><th scope=col>ols_lasso_rdos</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>mse_train</th><td>0.2019455</td><td>0.2019257</td><td>0.2019455</td><td>0.2021324</td><td>0.2019577</td><td>0.2022936</td><td>0.2298293</td><td>0.2024417</td><td>0.2020678</td></tr>\n",
       "\t<tr><th scope=row>mse_test</th><td>0.2012196</td><td>0.2014333</td><td>0.2012196</td><td>0.2014002</td><td>0.2012192</td><td>0.2013742</td><td>0.2016662</td><td>0.2016733</td><td>0.2012652</td></tr>\n",
       "\t<tr><th scope=row>f1</th><td>0.5095327</td><td>0.5027429</td><td>0.5095327</td><td>0.5113143</td><td>0.5105867</td><td>0.5100535</td><td>0.5046585</td><td>0.5045114</td><td>0.5089586</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 9 of type dbl\n",
       "\\begin{tabular}{r|lllllllll}\n",
       "  & ols\\_rdos & logit\\_rdos & svm\\_rdos & ridge\\_rdos & lasso\\_rdos & lasso2\\_rdos & lasso\\_logit\\_rdos & elastnet\\_logit\\_rdos & ols\\_lasso\\_rdos\\\\\n",
       "\\hline\n",
       "\tmse\\_train & 0.2019455 & 0.2019257 & 0.2019455 & 0.2021324 & 0.2019577 & 0.2022936 & 0.2298293 & 0.2024417 & 0.2020678\\\\\n",
       "\tmse\\_test & 0.2012196 & 0.2014333 & 0.2012196 & 0.2014002 & 0.2012192 & 0.2013742 & 0.2016662 & 0.2016733 & 0.2012652\\\\\n",
       "\tf1 & 0.5095327 & 0.5027429 & 0.5095327 & 0.5113143 & 0.5105867 & 0.5100535 & 0.5046585 & 0.5045114 & 0.5089586\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 9 of type dbl\n",
       "\n",
       "| <!--/--> | ols_rdos | logit_rdos | svm_rdos | ridge_rdos | lasso_rdos | lasso2_rdos | lasso_logit_rdos | elastnet_logit_rdos | ols_lasso_rdos |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| mse_train | 0.2019455 | 0.2019257 | 0.2019455 | 0.2021324 | 0.2019577 | 0.2022936 | 0.2298293 | 0.2024417 | 0.2020678 |\n",
       "| mse_test | 0.2012196 | 0.2014333 | 0.2012196 | 0.2014002 | 0.2012192 | 0.2013742 | 0.2016662 | 0.2016733 | 0.2012652 |\n",
       "| f1 | 0.5095327 | 0.5027429 | 0.5095327 | 0.5113143 | 0.5105867 | 0.5100535 | 0.5046585 | 0.5045114 | 0.5089586 |\n",
       "\n"
      ],
      "text/plain": [
       "          ols_rdos  logit_rdos svm_rdos  ridge_rdos lasso_rdos lasso2_rdos\n",
       "mse_train 0.2019455 0.2019257  0.2019455 0.2021324  0.2019577  0.2022936  \n",
       "mse_test  0.2012196 0.2014333  0.2012196 0.2014002  0.2012192  0.2013742  \n",
       "f1        0.5095327 0.5027429  0.5095327 0.5113143  0.5105867  0.5100535  \n",
       "          lasso_logit_rdos elastnet_logit_rdos ols_lasso_rdos\n",
       "mse_train 0.2298293        0.2024417           0.2020678     \n",
       "mse_test  0.2016662        0.2016733           0.2012652     \n",
       "f1        0.5046585        0.5045114           0.5089586     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rdos <- cbind(rdos, ols_lasso_rdos)\n",
    "rdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f9f342-978d-4f64-b6cb-fdd4cf3fa951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
